{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
       "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
       "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
       "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
       "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
       "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
       "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
       "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
       "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
       "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
       "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition', 'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\Sowmya\\Personal\\PYTORCH\\Pytorch_stuffs\\houseprice.csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\Sowmya\\Personal\\PYTORCH\\Pytorch_stuffs\\houseprice.csv\", usecols=[\"SalePrice\", \"MSSubClass\", 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'LotShape']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1201, 10)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>2003</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>1976</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>2001</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>1915</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>2000</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape  YearBuilt  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg       2003   \n",
       "1          20       RL         80.0     9600   Pave      Reg       1976   \n",
       "2          60       RL         68.0    11250   Pave      IR1       2001   \n",
       "3          70       RL         60.0     9550   Pave      IR1       1915   \n",
       "4          60       RL         84.0    14260   Pave      IR1       2000   \n",
       "\n",
       "   1stFlrSF  2ndFlrSF  SalePrice  \n",
       "0       856       854     208500  \n",
       "1      1262         0     181500  \n",
       "2       920       866     223500  \n",
       "3       961       756     140000  \n",
       "4      1145      1053     250000  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column name : MSSubClass, unique values are 15\n",
      "Column name : MSZoning, unique values are 5\n",
      "Column name : LotFrontage, unique values are 110\n",
      "Column name : LotArea, unique values are 869\n",
      "Column name : Street, unique values are 2\n",
      "Column name : LotShape, unique values are 4\n",
      "Column name : YearBuilt, unique values are 112\n",
      "Column name : 1stFlrSF, unique values are 678\n",
      "Column name : 2ndFlrSF, unique values are 368\n",
      "Column name : SalePrice, unique values are 597\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(f\"Column name : {i}, unique values are {len(df[i].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1201 entries, 0 to 1459\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   MSSubClass   1201 non-null   int64  \n",
      " 1   MSZoning     1201 non-null   object \n",
      " 2   LotFrontage  1201 non-null   float64\n",
      " 3   LotArea      1201 non-null   int64  \n",
      " 4   Street       1201 non-null   object \n",
      " 5   LotShape     1201 non-null   object \n",
      " 6   YearBuilt    1201 non-null   int64  \n",
      " 7   1stFlrSF     1201 non-null   int64  \n",
      " 8   2ndFlrSF     1201 non-null   int64  \n",
      " 9   SalePrice    1201 non-null   int64  \n",
      "dtypes: float64(1), int64(6), object(3)\n",
      "memory usage: 103.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "datetime.now().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total years'] = datetime.now().year - df['YearBuilt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Total years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>2003</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>208500</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>1976</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>181500</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>2001</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>223500</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>1915</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>140000</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>2000</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>250000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape  YearBuilt  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg       2003   \n",
       "1          20       RL         80.0     9600   Pave      Reg       1976   \n",
       "2          60       RL         68.0    11250   Pave      IR1       2001   \n",
       "3          70       RL         60.0     9550   Pave      IR1       1915   \n",
       "4          60       RL         84.0    14260   Pave      IR1       2000   \n",
       "\n",
       "   1stFlrSF  2ndFlrSF  SalePrice  Total years  \n",
       "0       856       854     208500           21  \n",
       "1      1262         0     181500           48  \n",
       "2       920       866     223500           23  \n",
       "3       961       756     140000          109  \n",
       "4      1145      1053     250000           24  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"YearBuilt\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'LotShape', '1stFlrSF', '2ndFlrSF', 'SalePrice', 'Total years'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\"MSSubClass\", \"MSZoning\", \"Street\", \"LotShape\"]\n",
    "out_feature = \"SalePrice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 5, ..., 6, 0, 0])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbl_encoders = {}\n",
    "lbl_encoders[\"MSSubClass\"] = LabelEncoder()\n",
    "lbl_encoders[\"MSSubClass\"].fit_transform(df[\"MSSubClass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSSubClass': LabelEncoder()}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lbl_encoders = {}\n",
    "for feature in cat_features:\n",
    "    lbl_encoders[feature] = LabelEncoder()\n",
    "    df[feature] = lbl_encoders[feature].fit_transform(df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSSubClass': LabelEncoder(),\n",
       " 'MSZoning': LabelEncoder(),\n",
       " 'Street': LabelEncoder(),\n",
       " 'LotShape': LabelEncoder()}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Total years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>208500</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>181500</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>223500</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>140000</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>250000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  MSZoning  LotFrontage  LotArea  Street  LotShape  1stFlrSF  \\\n",
       "0           5         3         65.0     8450       1         3       856   \n",
       "1           0         3         80.0     9600       1         3      1262   \n",
       "2           5         3         68.0    11250       1         0       920   \n",
       "3           6         3         60.0     9550       1         0       961   \n",
       "4           5         3         84.0    14260       1         0      1145   \n",
       "\n",
       "   2ndFlrSF  SalePrice  Total years  \n",
       "0       854     208500           21  \n",
       "1         0     181500           48  \n",
       "2       866     223500           23  \n",
       "3       756     140000          109  \n",
       "4      1053     250000           24  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 3, 1, 3],\n",
       "       [0, 3, 1, 3],\n",
       "       [5, 3, 1, 0],\n",
       "       ...,\n",
       "       [6, 3, 1, 3],\n",
       "       [0, 3, 1, 3],\n",
       "       [0, 3, 1, 3]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Stacking and converting into Tensors\n",
    "cat_features = np.stack([df['MSSubClass'], df['MSZoning'], df['Street'], df['LotShape']], 1)\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 3, 1, 3],\n",
       "        [0, 3, 1, 3],\n",
       "        [5, 3, 1, 0],\n",
       "        ...,\n",
       "        [6, 3, 1, 3],\n",
       "        [0, 3, 1, 3],\n",
       "        [0, 3, 1, 3]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert numpy to tensors\n",
    "import torch\n",
    "cat_features = torch.tensor(cat_features, dtype=torch.int64)\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create contineous features\n",
    "cont_features = []\n",
    "\n",
    "for i in df.columns:\n",
    "    if i in [\"MSSubClass\", \"MSZoning\", \"Street\", \"LotShape\", \"SalePrice\"]:\n",
    "        pass\n",
    "    else:\n",
    "        cont_features.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LotFrontage', 'LotArea', '1stFlrSF', '2ndFlrSF', 'Total years']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   65.,  8450.,   856.,   854.,    21.],\n",
       "        [   80.,  9600.,  1262.,     0.,    48.],\n",
       "        [   68., 11250.,   920.,   866.,    23.],\n",
       "        ...,\n",
       "        [   66.,  9042.,  1188.,  1152.,    83.],\n",
       "        [   68.,  9717.,  1078.,     0.,    74.],\n",
       "        [   75.,  9937.,  1256.,     0.,    59.]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_values = np.stack([df[i].values for i in cont_features], axis=1)\n",
    "cont_values = torch.tensor(cont_values, dtype=torch.float)\n",
    "cont_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_values.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([208500., 181500., 223500.,  ..., 266500., 142125., 147500.])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dependent feature\n",
    "y = torch.tensor(df['SalePrice'].values, dtype=torch.float)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[208500.],\n",
       "        [181500.],\n",
       "        [223500.],\n",
       "        ...,\n",
       "        [266500.],\n",
       "        [142125.],\n",
       "        [147500.]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor(df['SalePrice'].values, dtype=torch.float).reshape(-1, 1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1201 entries, 0 to 1459\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   MSSubClass   1201 non-null   int64  \n",
      " 1   MSZoning     1201 non-null   int64  \n",
      " 2   LotFrontage  1201 non-null   float64\n",
      " 3   LotArea      1201 non-null   int64  \n",
      " 4   Street       1201 non-null   int64  \n",
      " 5   LotShape     1201 non-null   int64  \n",
      " 6   1stFlrSF     1201 non-null   int64  \n",
      " 7   2ndFlrSF     1201 non-null   int64  \n",
      " 8   SalePrice    1201 non-null   int64  \n",
      " 9   Total years  1201 non-null   int64  \n",
      "dtypes: float64(1), int64(9)\n",
      "memory usage: 103.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1201, 4]), torch.Size([1201, 5]), torch.Size([1201, 1]))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features.shape, cont_values.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1201, 10)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding size for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 5, 2, 4]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dims = [len(df[col].unique()) for col in [\"MSSubClass\", \"MSZoning\", \"Street\", \"LotShape\"]]\n",
    "cat_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15, 8), (5, 3), (2, 1), (4, 2)]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Thumb Rule: Output dimensio should be set based on the input dimension (min(50, feature dimension/2))\n",
    "embedding_dim = [(x, min(50, (x+1) // 2)) for x in cat_dims]\n",
    "embedding_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =================== Preprocessing step completed ==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(15, 8)\n",
       "  (1): Embedding(5, 3)\n",
       "  (2): Embedding(2, 1)\n",
       "  (3): Embedding(4, 2)\n",
       ")"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "embed_representation = nn.ModuleList([nn.Embedding(inp, out) for inp, out in embedding_dim])\n",
    "embed_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 3, 1, 3],\n",
       "        [0, 3, 1, 3],\n",
       "        [5, 3, 1, 0],\n",
       "        ...,\n",
       "        [6, 3, 1, 3],\n",
       "        [0, 3, 1, 3],\n",
       "        [0, 3, 1, 3]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 3, 1, 3],\n",
       "        [0, 3, 1, 3],\n",
       "        [5, 3, 1, 0],\n",
       "        [6, 3, 1, 0]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "embedding_val = []\n",
    "for i, e in enumerate(embed_representation):\n",
    "    embedding_val.append(e(cat_features[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.9116,  1.1317, -0.0168,  ...,  0.0714, -1.2682,  1.1747],\n",
       "         [ 0.6315, -0.1799,  0.3308,  ..., -1.0245, -0.2796,  1.0294],\n",
       "         [-0.9116,  1.1317, -0.0168,  ...,  0.0714, -1.2682,  1.1747],\n",
       "         ...,\n",
       "         [-1.9004, -1.2638,  2.6713,  ..., -1.2084, -1.4775,  0.2661],\n",
       "         [ 0.6315, -0.1799,  0.3308,  ..., -1.0245, -0.2796,  1.0294],\n",
       "         [ 0.6315, -0.1799,  0.3308,  ..., -1.0245, -0.2796,  1.0294]],\n",
       "        grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[ 0.0572,  1.1361, -1.1297],\n",
       "         [ 0.0572,  1.1361, -1.1297],\n",
       "         [ 0.0572,  1.1361, -1.1297],\n",
       "         ...,\n",
       "         [ 0.0572,  1.1361, -1.1297],\n",
       "         [ 0.0572,  1.1361, -1.1297],\n",
       "         [ 0.0572,  1.1361, -1.1297]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[0.6653],\n",
       "         [0.6653],\n",
       "         [0.6653],\n",
       "         ...,\n",
       "         [0.6653],\n",
       "         [0.6653],\n",
       "         [0.6653]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[1.2910, 2.2201],\n",
       "         [1.2910, 2.2201],\n",
       "         [1.1728, 0.6808],\n",
       "         ...,\n",
       "         [1.2910, 2.2201],\n",
       "         [1.2910, 2.2201],\n",
       "         [1.2910, 2.2201]], grad_fn=<EmbeddingBackward0>)]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9116,  1.1317, -0.0168,  ...,  0.6653,  1.2910,  2.2201],\n",
       "        [ 0.6315, -0.1799,  0.3308,  ...,  0.6653,  1.2910,  2.2201],\n",
       "        [-0.9116,  1.1317, -0.0168,  ...,  0.6653,  1.1728,  0.6808],\n",
       "        ...,\n",
       "        [-1.9004, -1.2638,  2.6713,  ...,  0.6653,  1.2910,  2.2201],\n",
       "        [ 0.6315, -0.1799,  0.3308,  ...,  0.6653,  1.2910,  2.2201],\n",
       "        [ 0.6315, -0.1799,  0.3308,  ...,  0.6653,  1.2910,  2.2201]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.cat(embedding_val, 1)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement dropout\n",
    "\n",
    "dropout = nn.Dropout(.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000,  1.8862, -0.0000,  ...,  0.0000,  0.0000,  3.7001],\n",
       "        [ 0.0000, -0.0000,  0.5513,  ...,  1.1089,  0.0000,  0.0000],\n",
       "        [-1.5193,  1.8862, -0.0280,  ...,  1.1089,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [-3.1673, -0.0000,  0.0000,  ...,  0.0000,  0.0000,  3.7001],\n",
       "        [ 0.0000, -0.2999,  0.5513,  ...,  1.1089,  2.1517,  0.0000],\n",
       "        [ 0.0000, -0.2999,  0.5513,  ...,  0.0000,  2.1517,  3.7001]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embed = dropout(z)\n",
    "final_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FeedForwardNN(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(inp, out) for inp, out in embedding_dim])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "\n",
    "        layerlist = []\n",
    "        n_emb = sum((out for inp, out in embedding_dim))\n",
    "        n_in = n_emb + n_cont\n",
    "\n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in, i))\n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1], out_sz))\n",
    "\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = []\n",
    "        for i, e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:, i]))\n",
    "        \n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "\n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cont_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(100)\n",
    "model = FeedForwardNN(embedding_dim, len(cont_features), 1, [100, 50], p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedForwardNN(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(15, 8)\n",
       "    (1): Embedding(5, 3)\n",
       "    (2): Embedding(2, 1)\n",
       "    (3): Embedding(4, 2)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.5, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=19, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1201, 10)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   65.,  8450.,   856.,   854.,    21.],\n",
       "        [   80.,  9600.,  1262.,     0.,    48.],\n",
       "        [   68., 11250.,   920.,   866.,    23.],\n",
       "        ...,\n",
       "        [   66.,  9042.,  1188.,  1152.,    83.],\n",
       "        [   68.,  9717.,  1078.,     0.,    74.],\n",
       "        [   75.,  9937.,  1256.,     0.,    59.]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1201, 5])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1200\n",
    "\n",
    "test_size = int(batch_size*0.15)\n",
    "\n",
    "train_categorical = cat_features[:batch_size-test_size]\n",
    "test_categorical = cat_features[batch_size-test_size:batch_size]\n",
    "\n",
    "train_cont = cont_values[:batch_size-test_size]\n",
    "test_cont = cont_values[batch_size-test_size:batch_size]\n",
    "\n",
    "y_train = y[:batch_size-test_size]\n",
    "y_test = y[batch_size-test_size:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1020, 180, 1020, 180, 1020, 180)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_categorical), len(test_categorical), len(train_cont), len(test_cont), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 1 and the loss: 200496.78125\n",
      "Epoch number: 11 and the loss: 200493.65625\n",
      "Epoch number: 21 and the loss: 200489.265625\n",
      "Epoch number: 31 and the loss: 200482.890625\n",
      "Epoch number: 41 and the loss: 200473.875\n",
      "Epoch number: 51 and the loss: 200461.765625\n",
      "Epoch number: 61 and the loss: 200446.96875\n",
      "Epoch number: 71 and the loss: 200430.09375\n",
      "Epoch number: 81 and the loss: 200409.25\n",
      "Epoch number: 91 and the loss: 200384.9375\n",
      "Epoch number: 101 and the loss: 200356.484375\n",
      "Epoch number: 111 and the loss: 200324.296875\n",
      "Epoch number: 121 and the loss: 200293.015625\n",
      "Epoch number: 131 and the loss: 200253.515625\n",
      "Epoch number: 141 and the loss: 200208.8125\n",
      "Epoch number: 151 and the loss: 200162.46875\n",
      "Epoch number: 161 and the loss: 200116.03125\n",
      "Epoch number: 171 and the loss: 200063.953125\n",
      "Epoch number: 181 and the loss: 200009.9375\n",
      "Epoch number: 191 and the loss: 199951.625\n",
      "Epoch number: 201 and the loss: 199882.5\n",
      "Epoch number: 211 and the loss: 199822.75\n",
      "Epoch number: 221 and the loss: 199744.125\n",
      "Epoch number: 231 and the loss: 199673.71875\n",
      "Epoch number: 241 and the loss: 199598.03125\n",
      "Epoch number: 251 and the loss: 199505.109375\n",
      "Epoch number: 261 and the loss: 199405.0625\n",
      "Epoch number: 271 and the loss: 199342.984375\n",
      "Epoch number: 281 and the loss: 199255.390625\n",
      "Epoch number: 291 and the loss: 199136.015625\n",
      "Epoch number: 301 and the loss: 199042.421875\n",
      "Epoch number: 311 and the loss: 198932.546875\n",
      "Epoch number: 321 and the loss: 198842.859375\n",
      "Epoch number: 331 and the loss: 198700.828125\n",
      "Epoch number: 341 and the loss: 198602.78125\n",
      "Epoch number: 351 and the loss: 198513.796875\n",
      "Epoch number: 361 and the loss: 198386.109375\n",
      "Epoch number: 371 and the loss: 198253.875\n",
      "Epoch number: 381 and the loss: 198097.25\n",
      "Epoch number: 391 and the loss: 198029.21875\n",
      "Epoch number: 401 and the loss: 197891.0\n",
      "Epoch number: 411 and the loss: 197752.546875\n",
      "Epoch number: 421 and the loss: 197586.46875\n",
      "Epoch number: 431 and the loss: 197452.453125\n",
      "Epoch number: 441 and the loss: 197277.28125\n",
      "Epoch number: 451 and the loss: 197142.609375\n",
      "Epoch number: 461 and the loss: 196948.953125\n",
      "Epoch number: 471 and the loss: 196926.546875\n",
      "Epoch number: 481 and the loss: 196698.640625\n",
      "Epoch number: 491 and the loss: 196479.671875\n",
      "Epoch number: 501 and the loss: 196426.9375\n",
      "Epoch number: 511 and the loss: 196239.421875\n",
      "Epoch number: 521 and the loss: 196065.234375\n",
      "Epoch number: 531 and the loss: 195837.671875\n",
      "Epoch number: 541 and the loss: 195690.53125\n",
      "Epoch number: 551 and the loss: 195474.75\n",
      "Epoch number: 561 and the loss: 195293.15625\n",
      "Epoch number: 571 and the loss: 195045.65625\n",
      "Epoch number: 581 and the loss: 194817.640625\n",
      "Epoch number: 591 and the loss: 194632.453125\n",
      "Epoch number: 601 and the loss: 194594.109375\n",
      "Epoch number: 611 and the loss: 194359.953125\n",
      "Epoch number: 621 and the loss: 194080.75\n",
      "Epoch number: 631 and the loss: 193857.6875\n",
      "Epoch number: 641 and the loss: 193646.78125\n",
      "Epoch number: 651 and the loss: 193513.21875\n",
      "Epoch number: 661 and the loss: 193261.609375\n",
      "Epoch number: 671 and the loss: 193115.25\n",
      "Epoch number: 681 and the loss: 192815.0625\n",
      "Epoch number: 691 and the loss: 192513.46875\n",
      "Epoch number: 701 and the loss: 192286.765625\n",
      "Epoch number: 711 and the loss: 192254.34375\n",
      "Epoch number: 721 and the loss: 192019.765625\n",
      "Epoch number: 731 and the loss: 191594.40625\n",
      "Epoch number: 741 and the loss: 191507.375\n",
      "Epoch number: 751 and the loss: 191203.734375\n",
      "Epoch number: 761 and the loss: 191007.921875\n",
      "Epoch number: 771 and the loss: 190832.71875\n",
      "Epoch number: 781 and the loss: 190518.078125\n",
      "Epoch number: 791 and the loss: 190269.734375\n",
      "Epoch number: 801 and the loss: 189966.734375\n",
      "Epoch number: 811 and the loss: 189677.765625\n",
      "Epoch number: 821 and the loss: 189735.578125\n",
      "Epoch number: 831 and the loss: 189285.109375\n",
      "Epoch number: 841 and the loss: 189035.53125\n",
      "Epoch number: 851 and the loss: 188903.859375\n",
      "Epoch number: 861 and the loss: 188469.109375\n",
      "Epoch number: 871 and the loss: 188164.515625\n",
      "Epoch number: 881 and the loss: 188007.5\n",
      "Epoch number: 891 and the loss: 187512.34375\n",
      "Epoch number: 901 and the loss: 187553.09375\n",
      "Epoch number: 911 and the loss: 187374.8125\n",
      "Epoch number: 921 and the loss: 186642.25\n",
      "Epoch number: 931 and the loss: 186516.609375\n",
      "Epoch number: 941 and the loss: 186319.8125\n",
      "Epoch number: 951 and the loss: 185919.15625\n",
      "Epoch number: 961 and the loss: 185586.921875\n",
      "Epoch number: 971 and the loss: 185309.84375\n",
      "Epoch number: 981 and the loss: 185129.8125\n",
      "Epoch number: 991 and the loss: 184713.8125\n",
      "Epoch number: 1001 and the loss: 184500.5\n",
      "Epoch number: 1011 and the loss: 184048.078125\n",
      "Epoch number: 1021 and the loss: 183836.359375\n",
      "Epoch number: 1031 and the loss: 183613.796875\n",
      "Epoch number: 1041 and the loss: 183274.15625\n",
      "Epoch number: 1051 and the loss: 183039.453125\n",
      "Epoch number: 1061 and the loss: 182532.75\n",
      "Epoch number: 1071 and the loss: 182456.4375\n",
      "Epoch number: 1081 and the loss: 182215.609375\n",
      "Epoch number: 1091 and the loss: 181630.046875\n",
      "Epoch number: 1101 and the loss: 181375.25\n",
      "Epoch number: 1111 and the loss: 180775.671875\n",
      "Epoch number: 1121 and the loss: 180531.09375\n",
      "Epoch number: 1131 and the loss: 180631.578125\n",
      "Epoch number: 1141 and the loss: 180147.015625\n",
      "Epoch number: 1151 and the loss: 179599.03125\n",
      "Epoch number: 1161 and the loss: 179476.0\n",
      "Epoch number: 1171 and the loss: 179221.875\n",
      "Epoch number: 1181 and the loss: 178544.6875\n",
      "Epoch number: 1191 and the loss: 178008.90625\n",
      "Epoch number: 1201 and the loss: 178275.3125\n",
      "Epoch number: 1211 and the loss: 177608.453125\n",
      "Epoch number: 1221 and the loss: 177894.59375\n",
      "Epoch number: 1231 and the loss: 176367.078125\n",
      "Epoch number: 1241 and the loss: 176229.28125\n",
      "Epoch number: 1251 and the loss: 175791.40625\n",
      "Epoch number: 1261 and the loss: 175574.4375\n",
      "Epoch number: 1271 and the loss: 175760.296875\n",
      "Epoch number: 1281 and the loss: 174948.265625\n",
      "Epoch number: 1291 and the loss: 174635.125\n",
      "Epoch number: 1301 and the loss: 174334.359375\n",
      "Epoch number: 1311 and the loss: 173647.40625\n",
      "Epoch number: 1321 and the loss: 173059.59375\n",
      "Epoch number: 1331 and the loss: 173678.328125\n",
      "Epoch number: 1341 and the loss: 172975.015625\n",
      "Epoch number: 1351 and the loss: 172478.765625\n",
      "Epoch number: 1361 and the loss: 172141.796875\n",
      "Epoch number: 1371 and the loss: 172020.5\n",
      "Epoch number: 1381 and the loss: 171502.234375\n",
      "Epoch number: 1391 and the loss: 170452.109375\n",
      "Epoch number: 1401 and the loss: 170782.359375\n",
      "Epoch number: 1411 and the loss: 169835.484375\n",
      "Epoch number: 1421 and the loss: 169881.859375\n",
      "Epoch number: 1431 and the loss: 169420.90625\n",
      "Epoch number: 1441 and the loss: 168832.484375\n",
      "Epoch number: 1451 and the loss: 168817.59375\n",
      "Epoch number: 1461 and the loss: 168105.75\n",
      "Epoch number: 1471 and the loss: 167747.875\n",
      "Epoch number: 1481 and the loss: 167407.640625\n",
      "Epoch number: 1491 and the loss: 166974.953125\n",
      "Epoch number: 1501 and the loss: 166796.671875\n",
      "Epoch number: 1511 and the loss: 165391.8125\n",
      "Epoch number: 1521 and the loss: 165938.46875\n",
      "Epoch number: 1531 and the loss: 165451.453125\n",
      "Epoch number: 1541 and the loss: 164743.8125\n",
      "Epoch number: 1551 and the loss: 164844.828125\n",
      "Epoch number: 1561 and the loss: 163984.40625\n",
      "Epoch number: 1571 and the loss: 163660.765625\n",
      "Epoch number: 1581 and the loss: 163062.84375\n",
      "Epoch number: 1591 and the loss: 163136.75\n",
      "Epoch number: 1601 and the loss: 162649.375\n",
      "Epoch number: 1611 and the loss: 161464.46875\n",
      "Epoch number: 1621 and the loss: 161299.453125\n",
      "Epoch number: 1631 and the loss: 161001.5\n",
      "Epoch number: 1641 and the loss: 161106.59375\n",
      "Epoch number: 1651 and the loss: 160547.46875\n",
      "Epoch number: 1661 and the loss: 160421.921875\n",
      "Epoch number: 1671 and the loss: 159501.0\n",
      "Epoch number: 1681 and the loss: 159055.6875\n",
      "Epoch number: 1691 and the loss: 159017.953125\n",
      "Epoch number: 1701 and the loss: 157826.828125\n",
      "Epoch number: 1711 and the loss: 157373.640625\n",
      "Epoch number: 1721 and the loss: 157278.3125\n",
      "Epoch number: 1731 and the loss: 157274.59375\n",
      "Epoch number: 1741 and the loss: 156468.0625\n",
      "Epoch number: 1751 and the loss: 156275.65625\n",
      "Epoch number: 1761 and the loss: 154781.25\n",
      "Epoch number: 1771 and the loss: 155012.890625\n",
      "Epoch number: 1781 and the loss: 154861.109375\n",
      "Epoch number: 1791 and the loss: 154292.09375\n",
      "Epoch number: 1801 and the loss: 153682.65625\n",
      "Epoch number: 1811 and the loss: 153071.4375\n",
      "Epoch number: 1821 and the loss: 152585.984375\n",
      "Epoch number: 1831 and the loss: 152860.671875\n",
      "Epoch number: 1841 and the loss: 152176.640625\n",
      "Epoch number: 1851 and the loss: 150488.609375\n",
      "Epoch number: 1861 and the loss: 150952.796875\n",
      "Epoch number: 1871 and the loss: 150529.984375\n",
      "Epoch number: 1881 and the loss: 149268.203125\n",
      "Epoch number: 1891 and the loss: 148746.921875\n",
      "Epoch number: 1901 and the loss: 149077.921875\n",
      "Epoch number: 1911 and the loss: 149178.6875\n",
      "Epoch number: 1921 and the loss: 148234.140625\n",
      "Epoch number: 1931 and the loss: 147433.21875\n",
      "Epoch number: 1941 and the loss: 147118.5625\n",
      "Epoch number: 1951 and the loss: 146629.171875\n",
      "Epoch number: 1961 and the loss: 145806.0\n",
      "Epoch number: 1971 and the loss: 146103.34375\n",
      "Epoch number: 1981 and the loss: 146928.671875\n",
      "Epoch number: 1991 and the loss: 144787.0625\n"
     ]
    }
   ],
   "source": [
    "epochs = 2000\n",
    "final_losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i = i+1\n",
    "    y_pred = model(train_categorical, train_cont)\n",
    "    loss = torch.sqrt(loss_function(y_pred, y_train)) ## RMSE\n",
    "\n",
    "    final_losses.append(loss)\n",
    "    if i%10 == 1:\n",
    "        print(f\"Epoch number: {i} and the loss: {loss.item()}\")\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAGwCAYAAABrUCsdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABdzUlEQVR4nO3deXxM9/oH8M9MkskimURkk2azhliCkIgWVakgtRS3qCpF76WhJaqhWlp1UaqLpbS/20o3tfSWlqAiBCW2VJCQCEKoLIhkksg+398fbqamM4mEySzJ5/16zUvm+zxz8pwMmcc53/M9EiGEABERERE9NqmhCyAiIiJqKNhYEREREekIGysiIiIiHWFjRURERKQjbKyIiIiIdISNFREREZGOsLEiIiIi0hFzQxfQmCiVSty8eRN2dnaQSCSGLoeIiIhqQQiBgoICuLu7Qyqt+ZgUGys9unnzJjw9PQ1dBhERET2C69evw8PDo8YcNlZ6ZGdnB+D+GyOXyw1cDREREdWGQqGAp6en6nO8Jmys9Kjq9J9cLmdjRUREZGJqM42Hk9eJiIiIdISNFREREZGOsLEiIiIi0hE2VkREREQ6wsaKiIiISEfYWBERERHpCBsrIiIiIh1hY0VERESkI2ysiIiIiHSEjRURERGRjrCxIiIiItIRNlZEREREOsKbMDcA+cXlKCgph7lUCnMzCcylEpibSe//KZXATCqp1Y0jiYiI6PEYtLFaunQpfv75Z6SkpMDa2hq9evXChx9+CF9fX1VOSUkJZs+ejU2bNqG0tBShoaH4/PPP4erqqsrJyMjAtGnTcODAAdja2mLChAlYunQpzM3/2r24uDhEREQgOTkZnp6eeOeddzBx4kS1etauXYsVK1YgKysL/v7+WL16NQIDA+tUiyFsPJ6BD/ek1JhjYXa/wbL4X/NlbWEGG0tzNJGZwUZmjiaWZrCW3X9ub20BubUFHGws0NRGpvrTydYSzZrIIJWySSMiItLGoI3VwYMHER4ejh49eqCiogJvv/02BgwYgPPnz6NJkyYAgFmzZiE6Ohpbt26Fvb09pk+fjhEjRuDIkSMAgMrKSoSFhcHNzQ1Hjx5FZmYmXn75ZVhYWGDJkiUAgPT0dISFhWHq1Kn44YcfEBsbiylTpqB58+YIDQ0FAGzevBkRERFYv349goKC8OmnnyI0NBSpqalwcXGpVS2GIpUAVhZSVFQKVCiF1pzySoHySoESKAEAd1H+SN/LXCpBM1sZHJtYwsXOEu4OVmhubw03eys0t7eCR1MbuDtYwdLc7JH3h4iIyFRJhBDaP4kN4NatW3BxccHBgwfRp08f5Ofnw9nZGRs3bsSoUaMAACkpKWjfvj3i4+PRs2dP7N69G8899xxu3rypOnK0fv16REZG4tatW5DJZIiMjER0dDSSkpJU32vMmDHIy8vDnj17AABBQUHo0aMH1qxZAwBQKpXw9PTEjBkzMHfu3FrV8jAKhQL29vbIz8+HXC7X6c+uihAClcr7DVZ5pRKVyvsNVeX/nlcoBSoqlSgur0RRaSXulVWgqKwSxWUVKCqtRFFpBRQl5ci7V46798qRX1yGu/fKcbeoDLn3ylDbvy2uckt4N2uCFs2awNXeCn7N7dDG1Q5ejjawMOPUPiIiMh11+fw2qjlW+fn5AABHR0cAQEJCAsrLyxESEqLKadeuHby8vFTNTHx8PDp16qR2Oi40NBTTpk1DcnIyunbtivj4eLVtVOXMnDkTAFBWVoaEhATMmzdPFZdKpQgJCUF8fHyta/m70tJSlJaWqp4rFIpH/dHUmkQiuT/PygywstDtUaPySiVuFZQit6gMtwpLkaMowc28EmQrSnAzvwQ384rx591iFJdXIltRimxFKU6k56ptw0wqgXczG7R3k8PXzQ7t3OzQvrkcTzhY8xQjERGZPKNprJRKJWbOnIknn3wSHTt2BABkZWVBJpPBwcFBLdfV1RVZWVmqnL/Pcap6/rAchUKB4uJi3L17F5WVlVpzUlJSal3L3y1duhTvv/9+LX8Cxs/CTAp3B2u4O1hXmyOEQG5RGa7fLUZKpgKZ+SW4lFOI9NtFSL9dhOLySly5VYQrt4oQfS5T9TpbS3NVo9WuuRzt3OzQ6Ql7nTeHRERE9cloGqvw8HAkJSXh999/N3QpOjNv3jxERESonisUCnh6ehqwovonkUjQzNYSzWwt0cXTQS2mVApkF5QgLbsQKVkKpGQWICWrAJdyClFYWoGEa3eRcO2uKt/O0hyejjbwdLTGoI7N0aOFI56ooakjIiIyNKNorKZPn46dO3fi0KFD8PDwUI27ubmhrKwMeXl5akeKsrOz4ebmpso5ceKE2vays7NVsao/q8YezJHL5bC2toaZmRnMzMy05jy4jYfV8neWlpawtLSsw0+iYZNKJWhub43m9tbo09ZZNV5eqUT67SJcyFQgJasAKZkKnL2RjztFZTifqcD5TAV+S77/3thbWyDwfw3Ws36uCGzhyDlbRERkNAzaWAkhMGPGDGzbtg1xcXFo0aKFWjwgIAAWFhaIjY3FyJEjAQCpqanIyMhAcHAwACA4OBj//ve/kZOTo7p6LyYmBnK5HH5+fqqcXbt2qW07JiZGtQ2ZTIaAgADExsZi+PDhAO6fmoyNjcX06dNrXQs9GgszKdq62qGtqx2G/W+srEKJc3/m4XxmAU6m5+LyrUJcyFQgv7gcMefvN1lRR6+qtjG8izsmPdUCnZ6w55pdRERkMAa9KvC1117Dxo0b8csvv6itXWVvbw9r6/unfKZNm4Zdu3YhKioKcrkcM2bMAAAcPXoUwP3lFrp06QJ3d3csX74cWVlZGD9+PKZMmaK23ELHjh0RHh6OSZMmYf/+/Xj99dcRHR2tttzChAkT8MUXXyAwMBCffvoptmzZgpSUFNXcq4fV8jD6uCqwIcu7V4b4y3dwPD0Xp67l4nLO/Tlbf2dnaY6wzs0R3KoZhnR256R4IiJ6LHX5/DZoY1XdkYUNGzaoFu+sWpTzxx9/VFuU88HTb9euXcO0adMQFxeHJk2aYMKECVi2bJnGAqGzZs3C+fPn4eHhgXfffVdjgdA1a9aoFgjt0qULVq1ahaCgIFW8NrXUhI2VblVUKnHw4i0cvHgLSX/m44+MPI0cFztLBHg3xTPtXPBMOxc0s+WpWSIiqhuTaawaGzZW9eteWQV2nsnEL2f+xJFLd7Tm+DWXY3AnN7zQ3RMucis9V0hERKaIjZWRYmOlP0II3CurRFzqLWw5dR0XswuQmV+ikWdhJsHyUZ0R2sENNjKjuJaDiIiMDBsrI8XGyrBSswqw/uBlJN/Mx8XsQo14Vy8H/CPAE2Gdm8Pe2sIAFRIRkTFiY2Wk2FgZj1sFpVi+JwVXbheprZ1VZXgXd3T2cMCEXj4w4+R3IqJGjY2VkWJjZZxSshRYvPMClELg6GXNuVlOtjK0by7H2nHdILfikSwiosaGjZWRYmNl/IQQ2J+Sg8/jLms9kgUAH47shBHdPLgwKRFRI8HGykixsTIt2YoS/HgiA5/uS9Mad5Vb4pPRXdCzRTOulUVE1ICxsTJSbKxMV8K1XIxcF19tvKmNBfbPfhpNm8j0WBUREekDGysjxcbK9AkhkJpdgM0nr2PDkatac5aP7IwXejTsm20TETUmbKyMFBurhufKrUI8s/KgxrhjExm6eDpgWBd3hHZwg5WFmQGqIyIiXWBjZaTYWDVcWfklWL0/DT8cz9Aan96vNV7r14qLkBIRmSA2VkaKjVXDJ4TAxexCrD1wCb+euakRd7K1xCej/dG7jbMBqiMiokfBxspIsbFqXIQQOJx2Gy9/fUJrfGIvH8wd1I6nCYmIjBwbKyPFxqpxqqhUYu/5bHwedwlJfyo04s2ayLDhlR7o7OGg/+KIiOih2FgZKTZWBAC/p93GS18d1xpbNKwDxvf0hkTCdbGIiIwFGysjxcaKqggh8Mm+NKyK1b746I7pT6GTh72eqyIiIm3YWBkpNlakjVIp0GvZfmQpSjRiLwd7450wP5hLJVzdnYjIQNhYGSk2VlSTzPxiBC/dX208dfFAWJpzojsRkb6xsTJSbKyoNu4UlmLNgUtaV3bv5+uMryb04NErIiI9YmNlpNhYUV2tP3gZy3anaIxbmEmwd1Zf+DSz4UR3IqJ6xsbKSLGxokf13bFreHd7ktZY+tLBbK6IiOpRXT6/pXqqiYgew/ie3ri6LAwfDO+oEeu48DdMjjqJK7cKDVAZERE9iEes9IhHrEhXrufeQ+/lB7TGNr4ahEAfR5ib8f9NRES6wFOBRoqNFelSpVLgzI08bD11HT+euK4RT34/FE0sedNnIqLHxcbKSLGxovpy9PJtvPh/2ldz/8/L3RHi56rnioiIGg42VkaKjRXVt58SbuDNrWe0xna93ht+7vx7R0RUV2ysjBQbK9IHIQROpOdi9JfHNGL+HvbYHv4kryIkIqoDNlZGio0V6ZNSKbDvQjb++V2C1viJt/vDRW6l56qIiEwPl1sgIkilEgzo4Ibk90PR0qmJRjxwSSwifzoL/t+KiEh3eMRKj3jEigxFqRQQAE5n3MWo9fEa8a8mdEf/9pzgTkSkDY9YEZEaqVQCM6kE3X0ccX5RqEZ88jen0Gb+LihKyg1QHRFRw8HGiqiRsZGZ4/S7z+K/03rB2c5SNV5eKdD5vb2Y8eNpnh4kInpEPBWoRzwVSMYoLjUHEzec1Bhf+Q9/DPF3h8yc//8iosaNVwUaKTZWZKwqlQI7z97E+zvOI7eoTC02K6Qtpj/TGmZSLtFARI0TGysjxcaKTMEviX/ijU2JGuOBPo54b2gHLjJKRI0OJ68T0SMb1uUJXFw8CHNCfdXGT1zNxeBVh7Eu7rKBKiMiMn5srIhIg8xcivB+rZG+dDBCO6gvw/DhnhSM+88xXL1dZKDqiIiMFxsrIqqWRCLBF+O74/vJQWrjRy7dwdMfxeHb+KuGKYyIyEhxjpUecY4VmbpLOQUI+fiQ2lgPn6ZY82I3ONhYwNLczECVERHVH86xIqJ60drFDv95ubva2MmrdxG0JBa+7+zB0Uu3DVQZEZFxYGNFRHUS4ueKq8vC8NZAX43Yi/85jmNX7higKiIi48BTgXrEU4HU0FQqBRKu3cULX6jff9DKQoozCwfw1CARNQg8FUhEemEmlSCwhSOuLBmM1/u3UY2XlCvRdVEMlu9JwbU7vHqQiBoPHrHSIx6xoobu2p0i9F0RpzH+5oC2+GefVrw9DhGZJB6xIiKD8G7WBOlLB6PD31Zn/2jvRbR9Zzdu5hWjoKTcQNUREdU/HrHSIx6xosaipLwSl28V4rv4a9h08rpG/JfwJ+Hv6aD/woiIHgGPWBGRQVlZmKGDuz2WjeyM7eFPasSHrT2CZbtTwP/XEVFDw8aKiOpVF08HJL0finfC2quNrz94GS3m7cLRy7ehVLLBIqKGgacC9YinAqmxE0JgwS/J+O7YNbVxO0tznHwnBFYWXJ6BiIwPTwUSkVGSSCT4YHhH7IvoqzZeUFqBdu/uQWlFpYEqIyLSDYM2VocOHcKQIUPg7u4OiUSC7du3q8Wzs7MxceJEuLu7w8bGBgMHDkRaWppaTklJCcLDw9GsWTPY2tpi5MiRyM7OVsvJyMhAWFgYbGxs4OLigjlz5qCiokItJy4uDt26dYOlpSVat26NqKgojXrXrl0LHx8fWFlZISgoCCdOnNDJz4GosWntYos9M3trjPu+sweXcgoMUBERkW4YtLEqKiqCv78/1q5dqxETQmD48OG4cuUKfvnlF5w+fRre3t4ICQlBUdFfCw7OmjULO3bswNatW3Hw4EHcvHkTI0aMUMUrKysRFhaGsrIyHD16FN988w2ioqKwYMECVU56ejrCwsLQr18/JCYmYubMmZgyZQp+++03Vc7mzZsRERGBhQsX4o8//oC/vz9CQ0ORk5NTTz8dooatnZscaf8ehIm9fNTGQz4+BJ+50Zi/7RzO3cg3THFERI/IaOZYSSQSbNu2DcOHDwcAXLx4Eb6+vkhKSkKHDh0AAEqlEm5ubliyZAmmTJmC/Px8ODs7Y+PGjRg1ahQAICUlBe3bt0d8fDx69uyJ3bt347nnnsPNmzfh6uoKAFi/fj0iIyNx69YtyGQyREZGIjo6GklJSap6xowZg7y8POzZswcAEBQUhB49emDNmjWqWjw9PTFjxgzMnTu3VvvIOVZEmoQQeH/HeUQdvao1fnVZmH4LIiL6mwYxx6q0tBQAYGVlpRqTSqWwtLTE77//DgBISEhAeXk5QkJCVDnt2rWDl5cX4uPv37ssPj4enTp1UjVVABAaGgqFQoHk5GRVzoPbqMqp2kZZWRkSEhLUcqRSKUJCQlQ51e2DQqFQexCROolEgveGdkD60sHo385FIz5n6xmk3y7CvbIKLa8mIjIuRttYVTVI8+bNw927d1FWVoYPP/wQN27cQGZmJgAgKysLMpkMDg4Oaq91dXVFVlaWKufBpqoqXhWrKUehUKC4uBi3b99GZWWl1pyqbWizdOlS2Nvbqx6enp51/0EQNRISiQRfTeyBY/P6q41vTbiBfh/FwW/Bb7iYzflXRGTcjLaxsrCwwM8//4yLFy/C0dERNjY2OHDgAAYNGgSp1GjLVjNv3jzk5+erHteva65ATUTq3Oytqj39N2zNET1XQ0RUN0bdoQQEBCAxMRF5eXnIzMzEnj17cOfOHbRs2RIA4ObmhrKyMuTl5am9Ljs7G25ubqqcv18lWPX8YTlyuRzW1tZwcnKCmZmZ1pyqbWhjaWkJuVyu9iCi2tk/u6/GWHF5JeZsPcMV24nIaBl1Y1XF3t4ezs7OSEtLw6lTpzBs2DAA9xsvCwsLxMbGqnJTU1ORkZGB4OBgAEBwcDDOnTundvVeTEwM5HI5/Pz8VDkPbqMqp2obMpkMAQEBajlKpRKxsbGqHCLSrZbOtri6LAy/hD+JbyYFqsa3JtxAi3m78OWhywasjohIO4NeFVhYWIhLly4BALp27YqPP/4Y/fr1g6OjI7y8vLB161Y4OzvDy8sL586dwxtvvIGAgAD897//VW1j2rRp2LVrF6KioiCXyzFjxgwAwNGjRwHcX26hS5cucHd3x/Lly5GVlYXx48djypQpWLJkCYD7yy107NgR4eHhmDRpEvbv34/XX38d0dHRCA0NBXB/uYUJEybgiy++QGBgID799FNs2bIFKSkpGnOvqsOrAoke3e9pt/HSV8fVxhxsLHBqfgjMzUzi/4hEZKLq9PktDOjAgQMCgMZjwoQJQgghPvvsM+Hh4SEsLCyEl5eXeOedd0RpaanaNoqLi8Vrr70mmjZtKmxsbMTzzz8vMjMz1XKuXr0qBg0aJKytrYWTk5OYPXu2KC8v16ilS5cuQiaTiZYtW4oNGzZo1Lt69Wrh5eUlZDKZCAwMFMeOHavT/ubn5wsAIj8/v06vI6K//GPdUeEduVPjkV9cZujSiKiBqsvnt9GsY9UY8IgVkW4s3nke//k9XWP8g+EdMb6ntwEqIqKGrEGsY0VEVJ13nvPDpX8PwpOtm6mNv7s9CV//ns7J7URkMGysiMgkmZtJ8cOUnmoT2wFg0c7z+OboVZRXKg1UGRE1ZmysiMik9W3rjJQPBqqNvbfjPNrM343os5kGqoqIGis2VkRk8qwszDB/cHtYmEnUxsM3/oHos5lI+jMfSiVPDxJR/ePkdT3i5HWi+lVeqUSb+bu1xmY80xqzB/jquSIiagg4eZ2IGiULMykOv9UPno7WGrHV+y9hb3IWKnnkiojqEY9Y6RGPWBHpT969MnRZFKM19tvMPvB1s9NzRURkqnjEiogaPQcbGQ68+bTWWOinh/BxzEUcuXRbv0URUYPHxoqIGqwWTk0Q8WxbDPV314itik3DuP8c1/IqIqJHx8aKiBq01/u3waqxXXF1WZjW+BubTuu5IiJqyNhYEVGj8XtkP4R1bq429kviTfT7KA5fablFDhFRXXHyuh5x8jqRcbhXVoH+Kw8iM79Ebfz1/m0Q8WxbA1VFRMaKk9eJiGpgIzNH/Lz+GuOrYtPQZv4uHE67ZYCqiKghYGNFRI3WjulPwbuZjdpYeaXA+K9OIO9emYGqIiJTxsaKiBqtTh72ODinH64uC0NYJ/W5V10WxSDjzj3ezJmI6oSNFRERgFVju2qM9VlxAG3m78adwlIDVEREpoiNFRERADOpBCkfDNQaC1i8DxezC/RcERGZIjZWRET/Y2Vhhn0RfTEuyEsjNuCTQ+BF1ET0MOaGLoCIyJi0drHF4uEdIbe2QHFZJaKOXlXFWszbhb5tnbFqTFfY21gYrkgiMlpcx0qPuI4Vkek5nHYL4786oTZmbWGGC9WcNiSihofrWBER6UjvNs74dHQXtbHi8krsPHsTSiX/X0pE6ngqkIjoIYb6u+PanXu4fKsQv565CQCYvvE0gNPYM7M32rnxCDQR3cdTgXrEU4FEpu/opdt48T/H1cYOznka3s2aGKgiIqpvPBVIRFRPerV2QuTAdmpjfVfEwWduNP6bcMNAVRGRsWBjRURUR9OeboXEBc+iu3dTtfHZW8/g2p0iA1VFRMaAjRUR0SNwsJHhp2m9ILdSn6rad0UcrufeM1BVRGRobKyIiB7D2nHdNMZ6Lz+AF9bHI7eIN3Imamw4eV2POHmdqGGqqFSisLQCXRbFaMR2zngKDjYW8GhqY4DKiEgXOHmdiEiPzM2kcLCR4fKSwWjppH514HOrf8dTHx7Amv1puJlXbKAKiUhf2FgREemImVSCTf/qibBOzTViH+29iPFfHdfyKiJqSNhYERHpkIudFdaO64aoV3poxC7fKuJq7UQNHBsrIqJ68LSvC47MfQZrX1Sf3N7y7V3Ycuq6gaoiovrGxoqIqJ484WCNsM6apwXf+uksj1wRNVBsrIiI6tmX4wM0xsb95zjucjkGogaHjRURUT0b0MENZxYOwAA/V9VY/JU76PpBDMorlQasjIh0jY0VEZEe2Ftb4MuXu2uMz9yciLe3nUNKlsIAVRGRrrGxIiLSo84e9mrPo89mYuPxDAz89DCKSisMVBUR6QobKyIiPVozVvMWOFU6LPwN+1Oy9VgNEekab2mjR7ylDRE9yGdutNbxQB9HvNqnJULau0Aikei5KiL6O97ShojIBOyY/hTeH9pBY/zE1Vy8+u0pTPv+DwNURUSPw9zQBRARNVadPOzRycMeXb0cMHTNEY34nuQsA1RFRI+DR6yIiAyss4cDLv17ECIHttOIcTkGItPCxoqIyAiYm0kx7elW+PgFf7Xx1374A4t2nEfbd3Yj6c98A1VHRLXFxoqIyIiM6OaBhUP8VM9jzmfj6yPpKKtQ4rnVv6OkvNKA1RHRw7CxIiIyMq882QJ7ZvbWGhu25ggSrt1FWQVPERIZIzZWRERGqJ2bHPMGac65Ss0uwMh1R7FoZ7IBqiKih2FjRURkpP7VtxU2vhoEX1c7jdj3xzIMUBERPQwbKyIiI9arlRN+m9UH+yL6aMR+SriB8zcVUCq5zjORseA6VkREJqClk63G2JtbzwAAQtq74j8TNG/wTET6Z9AjVocOHcKQIUPg7u4OiUSC7du3q8ULCwsxffp0eHh4wNraGn5+fli/fr1aTklJCcLDw9GsWTPY2tpi5MiRyM5Wv9dWRkYGwsLCYGNjAxcXF8yZMwcVFeo3O42Li0O3bt1gaWmJ1q1bIyoqSqPetWvXwsfHB1ZWVggKCsKJEyd08nMgInoYqVSCq8vCMLCDm0Zs34VsfLgnBZ/HXcKBlBwDVEdEVQzaWBUVFcHf3x9r167VGo+IiMCePXvw/fff48KFC5g5cyamT5+OX3/9VZUza9Ys7NixA1u3bsXBgwdx8+ZNjBgxQhWvrKxEWFgYysrKcPToUXzzzTeIiorCggULVDnp6ekICwtDv379kJiYiJkzZ2LKlCn47bffVDmbN29GREQEFi5ciD/++AP+/v4IDQ1FTg5/iRGR/qwfH4Cjc5+BmVT9HoLr4i5j+Z5UvBJ10kCVERFgRDdhlkgk2LZtG4YPH64a69ixI0aPHo13331XNRYQEIBBgwZh8eLFyM/Ph7OzMzZu3IhRo0YBAFJSUtC+fXvEx8ejZ8+e2L17N5577jncvHkTrq6uAID169cjMjISt27dgkwmQ2RkJKKjo5GUlKT6PmPGjEFeXh727NkDAAgKCkKPHj2wZs0aAIBSqYSnpydmzJiBuXPn1mofeRNmItKVq7eL8PRHcVpj6UsH8+bNRDrUYG7C3KtXL/z666/4888/IYTAgQMHcPHiRQwYMAAAkJCQgPLycoSEhKhe065dO3h5eSE+Ph4AEB8fj06dOqmaKgAIDQ2FQqFAcnKyKufBbVTlVG2jrKwMCQkJajlSqRQhISGqHG1KS0uhUCjUHkREuuDj1ASrx3bVGhv46WGcuZ6n34KICICRN1arV6+Gn58fPDw8IJPJMHDgQKxduxZ9+ty/OiYrKwsymQwODg5qr3N1dUVWVpYq58GmqipeFaspR6FQoLi4GLdv30ZlZaXWnKptaLN06VLY29urHp6ennX/IRARVWOIvztOzg9BgHdTtfHU7AKMWHcU98oqqnklEdUXo2+sjh07hl9//RUJCQlYuXIlwsPDsW/fPkOXVivz5s1Dfn6+6nH9+nVDl0REDYyznSW+mxwIW0v1i7wrlQJ+C35DaQVvgUOkT0bbWBUXF+Ptt9/Gxx9/jCFDhqBz586YPn06Ro8ejY8++ggA4ObmhrKyMuTl5am9Njs7G25ubqqcv18lWPX8YTlyuRzW1tZwcnKCmZmZ1pyqbWhjaWkJuVyu9iAi0jUbmTni5jyNKU+10IiN/88JrnNFpEdG21iVl5ejvLwcUql6iWZmZlAq798jKyAgABYWFoiNjVXFU1NTkZGRgeDgYABAcHAwzp07p3b1XkxMDORyOfz8/FQ5D26jKqdqGzKZDAEBAWo5SqUSsbGxqhwiIkNysrXEm6G+GssxnLiai5Zv70Lgv03jSD+RqTPoAqGFhYW4dOmS6nl6ejoSExPh6OgILy8v9O3bF3PmzIG1tTW8vb1x8OBBfPvtt/j4448BAPb29pg8eTIiIiLg6OgIuVyOGTNmIDg4GD179gQADBgwAH5+fhg/fjyWL1+OrKwsvPPOOwgPD4elpSUAYOrUqVizZg3eeustTJo0Cfv378eWLVsQHR2tqi0iIgITJkxA9+7dERgYiE8//RRFRUV45ZVX9PgTIyKqnpWFGdaPD4DP3GiNWE5BKX5KuIFRAR4GqIyoEREGdODAAQFA4zFhwgQhhBCZmZli4sSJwt3dXVhZWQlfX1+xcuVKoVQqVdsoLi4Wr732mmjatKmwsbERzz//vMjMzFT7PlevXhWDBg0S1tbWwsnJScyePVuUl5dr1NKlSxchk8lEy5YtxYYNGzTqXb16tfDy8hIymUwEBgaKY8eO1Wl/8/PzBQCRn59fp9cREdXF5hMZouuivcI7cqfGo6i0/OEbICI1dfn8Npp1rBoDrmNFRPp0IVOBQZ8dVhtbPqoznu/6BCzMjHYmCJHRaTDrWBER0aNr31yOvbP6YPazbVVjb/10Fm3m78Z3x64ZsDKihuuxGquSkhJ88803+Pzzz5GWlqarmoiISEfautph+jOtNcbf3Z6ESqXAncJSA1RF1HDV+lRgREQEysvLsXr1agD3VyMPCgpCcnIybGxsUFFRoXYlHWniqUAiMpRbBaXo8bcrA1s6N8GVW0VY/1IABnasfukYosauXk4F7t27F88++6zq+Q8//IBr164hLS0Nd+/exT/+8Q8sXrz40asmIqJ642xniRNv98eqB26Dc+VWEQBg6vcJKCmvRGZ+saHKI2owar3cQkZGhmrdJ+B+ozVq1Ch4e3sDAN544w0MHjxY9xUSEZFOuMit8Gx7V62xjgt/Q4VSoInMDLOebYspvVvquTqihqHWR6ykUikePGt47Ngx1VpRAODg4IC7d+/qtjoiItIpa5mZ1vGK/63OXlRWicXRF/RZElGDUuvGqn379tixYwcAIDk5GRkZGejXr58qfu3aNY2bFBMRkfH5YFgHPNXaCaEdqv+dnV9crseKiBqOWp8KfOuttzBmzBhER0cjOTkZgwcPRosWf92XateuXQgMDKyXIomISHfGB/tgfLAPAGDihhOIS72lkRNzPpurtBM9glofsXr++eexa9cudO7cGbNmzcLmzZvV4jY2Nnjttdd0XiAREdWfpSM6aR1/c+sZAADXkCaqG668rkdcboGIjNGRS7cx7j/HtcZ8mtlg5+u9YWtp0FvLEhlUvSy3cPv2bVy7pr5Sb3JyMl555RW88MIL2Lhx46NVS0REBtWrVTN8NqYL4t58Gj18mqrFrt65h5jzWQaqjMj01LqxmjFjBlatWqV6npOTg969e+PkyZMoLS3FxIkT8d1339VLkUREVH8kEgmGdXkCPk5NMOuB299UmbX5DL44eNkAlRGZnlo3VseOHcPQoUNVz7/99ls4OjoiMTERv/zyC5YsWYK1a9fWS5FERKQfvVo5Yc2LXTXGl+5Owdgvj2HihhOcd0VUg1o3VllZWfDx8VE9379/P0aMGAFz8/vn3YcOHcr7BRIRNQBPtXbSOh5/5Q7iUm9xKQaiGtS6sZLL5cjLy1M9P3HiBIKCglTPJRIJSkt5M08iIlNnZ2UBmXn1Hw9dFsXgxxMZPHJFpEWtG6uePXti1apVUCqV+Omnn1BQUIBnnnlGFb948SI8PT3rpUgiItIfM6kEsRF9cXDO03g52Ftrzryfz+G3ZE5qJ/q7WjdWH3zwAX799VdYW1tj9OjReOutt9C06V9Xj2zatAl9+/atlyKJiEi/PB1t4N2sCd4f2gEfDOugNWfq93/gdiHPVBA9qE7rWN2+fRtHjhyBm5ub2mlAAIiOjoafn5/aauykjutYEZGpqm6FdgA48XZ/uMit9FwRkf7U5fObC4TqERsrIjJVF7MLMOenszhzPU9r/MKigdXe4JnI1NXLAqEAUFFRgRUrVqBbt26wtbWFra0tunXrho8++gjl5bxKhIiooWrraodfwp/Eifn9YW2h2UBNijppgKqIjE+tG6vi4mI8/fTTmDt3LpydnTFlyhRMmTIFzs7OiIyMRP/+/VFSUlKftRIRkYG52Fnh/KJQjfH4K3dw6mquASoiMi61vvnTsmXLcP36dZw+fRqdO3dWi505cwZDhw7FsmXL8N577+m6RiIiMiISiUTr+Kj18Vg3rhsGdWqu54qIjEetj1ht2rQJH3/8sUZTBQD+/v746KOPeL9AIqJGYsFzfhjexV1jfNoPf+Db+Kv4KeGGAaoiMrxaT163srJCWlpatWtVXb9+HW3atOHpwBpw8joRNTRHLt3G+zuScTG7UCP26/Qn0dnDQf9FEelYvUxel8vlyMnJqTaelZUFOzu72ldJREQm78nWTtg7qy9ef6a1Rqy6KwiJGrJaN1b9+vXDkiVLqo0vW7YM/fr100lRRERkWiIG+OLk/BC1sXd/SUbE5kSUlFcaqCoi/av15PWFCxciKCgIPXv2REREBNq1awchBC5cuIBPPvkE58+fx7Fjx+qzViIiMmLOdpYaYz+f/hM/n/4T5xeFwkZW648cIpNV6yNWfn5+iImJQUFBAcaMGYOuXbuiW7duePHFF1FQUIC9e/eiQwfttz0gIqLGYeeMp7SOfxabpudKiAzjkVZeT0xMxMWLFwEAbdu2RZcuXXDv3j0kJiaiV69eOi+yoeDkdSJqDNKyC/DsJ4fUxjq4y3GvrBJDOjdHxABfA1VG9GgMckubM2fOoFu3bqis5Ln06rCxIqLG5JujV7Hw12SN8XFBXhgf7I12bvw9SKah3m5pQ0REVFuje2hfnueH4xkYtS5ez9UQ6QcbKyIiqhdWFmZ4tXcLrbHC0gqEfnIIadkFeq6KqH6xsSIionrz9uD21cZSswsQ+d+zeqyGqP7V+trXX3/9tcZ4enr6YxdDREQNi0QiwfeTg/DSV8e1xv/IyEPSn/no+IS9nisjqh+1nrwulT784JZEIuHk9Rpw8joRNVYf703FF4euoLRCqTV+ZclgSKXab+5MZGgGuSqQHo6NFRE1ZqUVlUi4dhcv/p/2o1eH3+oHT0cbPVdF9HC8KpCIiIyOpbkZerVyQuKCZ7FuXDeN+ISvTxigKiLdYmNFRER65WAjQ8+WzTTGr9wugs/caNwtKjNAVUS6wcaKiIj0zsbSrNpY1w9ikFtUhv8cvoI7haV6rIro8fGOmEREpHcys5r/X9/tgxgAwMGLt/Dd5CB9lESkEzxiRUREeieRSLDhlR6wspBi9rNt4e/poDXvcNptTNxwAqUVvOKcTEOtG6sTJ07UuJRCaWkptmzZopOiiIio4evn64KUDwZhRv82+PgF/2rz4lJvYd/5HD1WRvToat1YBQcH486dO6rncrkcV65cUT3Py8vD2LFjdVsdERE1Cq2cbZH8fmi18YMXc1Cp5OpAZPxq3Vj9fbkrbctfcUksIiJ6VE0szfF81yfg6WiN8T291WJbTt1AwOIYFJfxlCAZN51OXpdIuGouERE9uk9GdwEAlFcq8d2xa2qxvHvlaL9gD/bO6oO2rnYGqI7o4Th5nYiIjI5FDVcNDvjkEErKeeSKjFOdjlidP38eWVlZAO6f9ktJSUFhYSEA4Pbt27qvjoiIGq12bnZIySrQGvNbsAcTevlg4ZAOeq6KqGZ1ugmzRCLROo+qapw3Ya4Z7xVIRFR7Qgic+zMfMnMpBn56WGvO1WVheq6KGqO6fH7X+ohVenr6YxdGRERUWxKJBJ09HDhhnUxKredYeXt71+pRF4cOHcKQIUPg7u4OiUSC7du3q8UlEonWx4oVK1Q5ubm5GDduHORyORwcHDB58mTV6ckqZ8+eRe/evWFlZQVPT08sX75co5atW7eiXbt2sLKyQqdOnbBr1y61uBACCxYsQPPmzWFtbY2QkBCkpaXVaX+JiKjurGXV3/7mvwk3sOFIOq9KJ6NR68bq9u3buHZN/QqN5ORkvPLKK3jhhRewcePGOn/zoqIi+Pv7Y+3atVrjmZmZao+vv/4aEokEI0eOVOWMGzcOycnJiImJwc6dO3Ho0CH885//VMUVCgUGDBgAb29vJCQkYMWKFXjvvffw5ZdfqnKOHj2KsWPHYvLkyTh9+jSGDx+O4cOHIykpSZWzfPlyrFq1CuvXr8fx48fRpEkThIaGoqSkpM77TUREdfPxC/6Y3q810pcOVhufvfUM3t9xHr2XH0BBSbmBqiP6S63nWI0dOxbu7u5YuXIlACAnJwft2rWDu7s7WrVqhd27d+Orr77C+PHjH60QiQTbtm3D8OHDq80ZPnw4CgoKEBsbCwC4cOEC/Pz8cPLkSXTv3h0AsGfPHgwePBg3btyAu7s71q1bh/nz5yMrKwsymQwAMHfuXGzfvh0pKSkAgNGjR6OoqAg7d+5Ufa+ePXuiS5cuWL9+PYQQcHd3x+zZs/Hmm28CAPLz8+Hq6oqoqCiMGTNGa72lpaUoLf3rBqIKhQKenp6cY0VE9BhmbU7EttN/aoxP7OWD94ZyMjvpXl3mWNX6iNWxY8cwdOhQ1fNvv/0Wjo6OSExMxC+//IIlS5ZUe+RJF7KzsxEdHY3JkyerxuLj4+Hg4KBqqgAgJCQEUqkUx48fV+X06dNH1VQBQGhoKFJTU3H37l1VTkhIiNr3Cw0NRXx8PID788uysrLUcuzt7REUFKTK0Wbp0qWwt7dXPTw9PR/jJ0BERACwdEQnreMHL97ScyVEmmrdWGVlZcHHx0f1fP/+/RgxYgTMze/Pfx86dGi9zjn65ptvYGdnhxEjRqjV5OLiopZnbm4OR0dH1bIQWVlZcHV1Vcupev6wnAfjD75OW4428+bNQ35+vupx/fr1Wu8vERFpZ2Vhhs/GdNEYT79dhOFrj3CNKzKoWjdWcrkceXl5qucnTpxAUFCQ6rlEIlE77aVrX3/9NcaNGwcrK6t6+x66ZmlpCblcrvYgIqLH91xnd63jidfzMPb/jum5GqK/1Lqx6tmzJ1atWgWlUomffvoJBQUFeOaZZ1Txixcv1tuprsOHDyM1NRVTpkxRG3dzc0NOjvodzysqKpCbmws3NzdVTnZ2tlpO1fOH5TwYf/B12nKIiEh/zKQSpC4eiFd7t4Dv325vczojD7lFZbhXVoHrufcMVCE1VrVurD744AP8+uuvsLa2xujRo/HWW2+hadOmqvimTZvQt2/feinyq6++QkBAAPz9/dXGg4ODkZeXh4SEBNXY/v37oVQqVUfTgoODcejQIZSX/3W1SExMDHx9fVX1BwcHqybEP5gTHBwMAGjRogXc3NzUchQKBY4fP67KISIi/bI0N8P8MD+sebGrRqzbBzEI+GAfei8/gPTbRQaojhqrWi8Q2rlzZ1y4cAFHjhyBm5ub2mlAABgzZgz8/Pzq9M0LCwtx6dIl1fP09HQkJibC0dERXl5eAO43MFu3blVdjfig9u3bY+DAgXj11Vexfv16lJeXY/r06RgzZgzc3e8fJn7xxRfx/vvvY/LkyYiMjERSUhI+++wzfPLJJ6rtvPHGG+jbty9WrlyJsLAwbNq0CadOnVItySCRSDBz5kwsXrwYbdq0QYsWLfDuu+/C3d29xqsYiYio/llZaF/nqvh/c63e+ukMtk7tpc+SqBGr9XIL9SEuLg79+vXTGJ8wYQKioqIAAF9++SVmzpyJzMxM2Nvba+Tm5uZi+vTp2LFjB6RSKUaOHIlVq1bB1tZWlXP27FmEh4fj5MmTcHJywowZMxAZGam2na1bt+Kdd97B1atX0aZNGyxfvhyDB/+1XooQAgsXLsSXX36JvLw8PPXUU/j888/Rtm3bWu8vb2lDRKR7twpK0ePf+2rMiZ3dF62cbWvMIapOXT6/a91Yffvtt7X65i+//HKt8hojNlZERLpXUFKOTu/trTFnw8Qe6NfOpcYcourUy70CJ06cCFtbW5ibm1d76wCJRMLGioiI9MrOygIv9fSCUgA384oRl6q5nlWlkre8If2o9RGrDh06IDs7Gy+99BImTZqEzp0713dtDQ6PWBER1a97ZRXYeSYTTZvI8Oq3p7Tm/DQ1GN19HPVcGZmyell5PTk5GdHR0SguLkafPn3QvXt3rFu3DgqF4rELJiIi0gUbmTle6OGJZ/1c8clof605o9ZXf8cMosdV68YKAIKCgvDFF18gMzMTr7/+OrZs2YLmzZtj3Lhx9bo4KBERUV1JJZJqY32WH6h2WgvR46hTY1XF2toaL7/8Mt5//30EBgZi06ZNuHePi7AREZHxCG7ZrNpYRu49bDhyVX/FUKNR58bqzz//xJIlS9CmTRuMGTMGPXr0QHJystpioURERIbmIrfCifn9ce69ARgX5KURX7TzPCe1k87V+qrALVu2YMOGDTh48CBCQ0NVi2mamWlfmI2IiMjQXOzu31/23893Qm5RGXYnZanF/7H+KAJbNEPPlo542pfLMdDjq/VVgVKpFF5eXhg3bhxcXV2rzXv99dd1VlxDw6sCiYgMJ/psJsI3/lFt/LeZfeDrZldtnBqvelkg1MfHB5IaJgIC99exunLlSu0rbWTYWBERGY4QAgcv3sLEDSe1xlf+wx8jAzz0XBWZgnpprOjxsbEiIjK867n3MP3H0zhzPU9t3N3eCocjn4GZtOaDCNT41Ms6VkRERA2Bp6MNtr+meVPmm/klmLk5Uf8FUYNS68Zq8ODByM/PVz1ftmwZ8vLyVM/v3LkDPz8/nRZHRERUHyQSCULaa05W33HmJvLvlRugImooan0q0MzMDJmZmXBxuf8XUS6XIzExES1btgQAZGdnw93dHZWVlfVXrYnjqUAiIuORW1SGgxdzMGvzGY1Yn7bOKCgpx5Z/BcPCjCd3Grt6ORX49/6LU7OIiMiUOTaR4fmuHtg7qw9ef6a1WuzQxVs4nZGHY1fuGKg6MlVsw4mIqFFr62qHiAG+WmPjvzqh52rI1NW6sZJIJBrLLTxs+QUiIiJT0cKpidbxsgqlnishU1brldeFEJg4cSIsLS0BACUlJZg6dSqaNLn/F5E3YSYiIlMWG9EXLd/epTH+7+jzaONqhxHdnoCNrNYfm9RI1Xry+iuvvFKrDW7YsOGxCmrIOHmdiMi43bh7D099eEBrbIi/O1aP7arnisgY1OXzu9atNxsmIiJq6Dya2lQb23HmJvq3c8Hwrk/osSIyNZy8TkREpEV376YaY1xAlB6GjRUREdEDpvZthXZudhgb6KU13u+jOEz55hSS/szXGqfGjfcK1CPOsSIiMh1Jf+bjudW/Vxt3sbPEifkheqyIDIX3CiQiInpMHZ+wx4cjO8HFzlJrPKegFFdvF+m5KjJ2PGKlRzxiRURkeoQQyCkoRdCSWK3x2c+2xbMdXNHOjb/XGyoesSIiItIRiURS7VErAFgZcxEDPz2sx4rImLGxIiIiegiJRIILiwbii/EBhi6FjBwbKyIiolqwlplhgJ8r/tWnpdb4v747hR+OX9NzVWRs2FgRERHVkkQiwbzB7TEzpI1G7LfkbMzflgROXW7c2FgRERHV0bSnW1UbK+VNmxs1NlZERER1ZGluVm3s4MVbeqyEjA0bKyIiokfQwqmJ1vF/fZcApZKnAxsrNlZERESP4L/TeuHrid2R8sFAhHVurhZr+fYupGUXGKgyMiQ2VkRERI/AsYkMz7RzhZWFGda+2E0j/uwnh7BybyruFpUZoDoyFDZWREREOvDtpECNsdX7L6HrBzHIKSgxQEVkCGysiIiIdKBPW2ekLx2sNbZ8T6qeqyFDYWNFRESkIxKJROv4Twk3kHHnnp6rIUNgY0VERKRDW/4VrHX8+c+PoLisUs/VkL6xsSIiItKhwBaO2B7+pMb4naIytF+wB4M+O4wLmQoDVEb6wMaKiIhIxzybWlcbu5CpwNyfz+mxGtInNlZEREQ61szWEv9+viMWPOenNZ5bVKrnikhfzA1dABERUUM0LsgbANDSuQkmbjhp4GpIX3jEioiIqB41sdQ8hnE9txjrD15G0p/5BqiI6hMbKyIionrU6Ql7uNtbaYwv252C51b/jrUHLqGotMIAlVF9YGNFRERUj6wszBA3p1+18RW/paLn0ljcLiyFELx5s6ljY0VERFTPZOZSfPQP/2rjBSUV6L54H97fcV6PVVF9YGNFRESkB6MCPKq95U2VqKNX9VMM1Rs2VkRERHoikUiw9sVu6NPWudqcyVEncf6mApVKgbtFZXqsjnRBInhCV28UCgXs7e2Rn58PuVxu6HKIiMiAfkq4gTe3ntEac7e3gp+7HPsu5CB2dl+0crbVc3X0oLp8fvOIFRERkQEM7uRWbexmfgn2XcgBAPxwLAMpWQoolTwOYgoM2lgdOnQIQ4YMgbu7OyQSCbZv366Rc+HCBQwdOhT29vZo0qQJevTogYyMDFW8pKQE4eHhaNasGWxtbTFy5EhkZ2erbSMjIwNhYWGwsbGBi4sL5syZg4oK9Utb4+Li0K1bN1haWqJ169aIiorSqGXt2rXw8fGBlZUVgoKCcOLECZ38HIiIqPGxkZnj6rIwvP5M6xrzvj6SjoGfHsbS3Rf0VBk9DoM2VkVFRfD398fatWu1xi9fvoynnnoK7dq1Q1xcHM6ePYt3330XVlZ/rQcya9Ys7NixA1u3bsXBgwdx8+ZNjBgxQhWvrKxEWFgYysrKcPToUXzzzTeIiorCggULVDnp6ekICwtDv379kJiYiJkzZ2LKlCn47bffVDmbN29GREQEFi5ciD/++AP+/v4IDQ1FTk5OPfxkiIiosYgY4FurvP87nI47hbwVjrEzmjlWEokE27Ztw/Dhw1VjY8aMgYWFBb777jutr8nPz4ezszM2btyIUaNGAQBSUlLQvn17xMfHo2fPnti9ezeee+453Lx5E66urgCA9evXIzIyErdu3YJMJkNkZCSio6ORlJSk9r3z8vKwZ88eAEBQUBB69OiBNWvWAACUSiU8PT0xY8YMzJ07V2t9paWlKC396x+BQqGAp6cn51gREZGa4rJKtF+w56F574S1x5TeLfVQET2oQcyxUiqViI6ORtu2bREaGgoXFxcEBQWpnS5MSEhAeXk5QkJCVGPt2rWDl5cX4uPjAQDx8fHo1KmTqqkCgNDQUCgUCiQnJ6tyHtxGVU7VNsrKypCQkKCWI5VKERISosrRZunSpbC3t1c9PD09H/0HQkREDZa1zAyLhnV4aF5phVIP1dDjMNrGKicnB4WFhVi2bBkGDhyIvXv34vnnn8eIESNw8OBBAEBWVhZkMhkcHBzUXuvq6oqsrCxVzoNNVVW8KlZTjkKhQHFxMW7fvo3KykqtOVXb0GbevHnIz89XPa5fv173HwQRETUKYwO9alyGAQBKyyv1VA09Ks07QxoJpfJ+Vz5s2DDMmjULANClSxccPXoU69evR9++fQ1ZXq1YWlrC0tLS0GUQEZEJsDCT4ttJgbh8qxBmEglOX7+LWZvVl2MoqVCirEIJmbnRHhdp9Iz2nXFycoK5uTn8/PzUxtu3b6+6KtDNzQ1lZWXIy8tTy8nOzoabm5sq5+9XCVY9f1iOXC6HtbU1nJycYGZmpjWnahtERES60MrZFj5OTeBkq/kf8y8PXUGXRXuRoygxQGVUG0bbWMlkMvTo0QOpqalq4xcvXoS3tzcAICAgABYWFoiNjVXFU1NTkZGRgeDgYABAcHAwzp07p3b1XkxMDORyuappCw4OVttGVU7VNmQyGQICAtRylEolYmNjVTlERES61NRGpnX8Xlklhq45oudqqLYMeiqwsLAQly5dUj1PT09HYmIiHB0d4eXlhTlz5mD06NHo06cP+vXrhz179mDHjh2Ii4sDANjb22Py5MmIiIiAo6Mj5HI5ZsyYgeDgYPTs2RMAMGDAAPj5+WH8+PFYvnw5srKy8M477yA8PFx1mm7q1KlYs2YN3nrrLUyaNAn79+/Hli1bEB0draotIiICEyZMQPfu3REYGIhPP/0URUVFeOWVV/T3AyMiokajfXM5+vk648bdYqTlFKrFshQlGPjpIex+ozckEomBKiSthAEdOHBAANB4TJgwQZXz1VdfidatWwsrKyvh7+8vtm/frraN4uJi8dprr4mmTZsKGxsb8fzzz4vMzEy1nKtXr4pBgwYJa2tr4eTkJGbPni3Ky8s1aunSpYuQyWSiZcuWYsOGDRr1rl69Wnh5eQmZTCYCAwPFsWPH6rS/+fn5AoDIz8+v0+uIiKjxylGUCO/InVofMclZhi6vUajL57fRrGPVGPBegURE9CjOXM/DD8evYcupG2rjYwO9sHREJwNV1XjU5fPbaK8KJCIiovv8PR1ga2Wu0Vj9eCID2YoSvNDdEwM78mIqY2C0k9eJiIjoL+ZS7XOp9qfkYOr3CcgtKgNPQhkeGysiIiIT4NnUBt29m6K7d1Ot8W4fxKDFvF34Lv6qfgsjNWysiIiITIBUKsHWqcHYOjUYHdyrn+fz7i/JeqyK/o6NFRERkYmQSCSQSCTY9tqThi6FqsHGioiIyMTIzKXY8EoPQ5dBWrCxIiIiMkH9fF3w0T/8sf6lAM3YR3HIv1dugKqIjRUREZGJGhXggdAOrhrj6beL4L9oL/7IuGuAqho3NlZEREQmTCKR4PVnWmuNjfj8KF76z3Fcz72n56oaLzZWREREJi5igC8uLBqoNfb7pduY+n0CKpVc40of2FgRERE1ANYys2pjyTcVmPZ9Am7mFeNmXrEeq2p8eEsbIiKiRmDv+WzsPZ8NALi4eBBk5jy2Uh/4UyUiImogFg/vCBc7y4fm3Sur0EM1jRMbKyIiogbipZ7eOP52/4fmVXC+Vb1hY0VERNSASCTab9b8oKz8EoRv/AOxF7L1UFHjIhG8FbbeKBQK2NvbIz8/H3J59fd5IiIiehyXbxXio99SsTsp66G5V5eF6aEi01aXz28esSIiImpgWjnbYliXJwxdRqPExoqIiKgBGuDnipX/8MfMkDY15oV8fBDZihI9VdXwsbEiIiJqgKRSCUYGeGBmSFvMCfWtNu9STiHmb0vSY2UNGxsrIiKiBm5iL58a4/s4iV1n2FgRERE1cE0szXF+USj6+TpXm3P08m09VtRwsbEiIiJqBGxk5tjwSmC18Rf/7zi4UMDjY2NFREREAIBP96UZugSTx8aKiIioEXlwvpXcSv2WwZ/FpiHjzj0UlvKWN4+KjRUREVEjMndQO4wN9IS7vRW+maR5arDPigN4/cfTBqisYTB/eAoRERE1FFYWZlg6onONOftTciCEqNXtcUgdj1gRERE1Yv9+vqPW8RbzdmHKNyf1XI3pY2NFRETUiI0L8sbht/ppje27kANFSbmeKzJtbKyIiIgaOSsLs2pji3ac12Mlpo+NFRERUSPnZCuDjUx7c3XlVqGeqzFtbKyIiIgaOYlEgo9f6KI19kdGHu6V3V9+YcvJ65gUdRJFXI6hWrwqkIiIiCCt4QJAvwW/IaxTc0SfywQAfPV7Ol7v30ZPlZkWHrEiIiIi9GnrDC9HG3g0tQYA/H2lhaqmCgCyFCX6LM2k8IgVERERwcrCDHFvPg2J5P6pwbe3ncPG4xlac28VlOq5OtPBI1ZEREQEAJBKJapFQZXK6m/IHHM+G/85fEVfZZkUNlZERESkoaKGxgoAFkdfQFp2gZ6qMR1srIiIiEhD5QON1el3n9WaM/rLY/oqx2SwsSIiIiINwS2bqb5u2kSGL8YHoGdLR7Wc3KIyVFQqEX02E18cvKzvEo0SJ68TERGRhpEBHrC0kKKbV1MAQGgHN4R2cEP/lXG4fKtIldd6/m7V1z1bNoO/p4O+SzUqPGJFREREGsykEgzr8gQ8HW3UxqNeCaz2NcPWHoEQNc/NaujYWBEREVGt/b3R+ru79xr3TZvZWBEREZHO8IgVERERUR2MCvCoNpaW07hv2szGioiIiOrko3/4VxubHHVSj5UYHzZWREREVGe73+itdbyorFLPlRgXNlZERERUZ+2by/FikJfWmM/caJy8mgsAuFtUhtKKxtNscR0rIiIieiQLnvPDyfRcrfOq/rE+XvW1p6M1Dr/1jD5LMxgesSIiIqJHYmVhhmf9XB+adz23WA/VGAeDNlaHDh3CkCFD4O7uDolEgu3bt6vFJ06cCIlEovYYOHCgWk5ubi7GjRsHuVwOBwcHTJ48GYWF6p3z2bNn0bt3b1hZWcHT0xPLly/XqGXr1q1o164drKys0KlTJ+zatUstLoTAggUL0Lx5c1hbWyMkJARpaWm6+UEQERGZKFe5Va3y4lJz6rkS42DQxqqoqAj+/v5Yu3ZttTkDBw5EZmam6vHjjz+qxceNG4fk5GTExMRg586dOHToEP75z3+q4gqFAgMGDIC3tzcSEhKwYsUKvPfee/jyyy9VOUePHsXYsWMxefJknD59GsOHD8fw4cORlJSkylm+fDlWrVqF9evX4/jx42jSpAlCQ0NRUlKiw58IERGRaRnq7w47y4fPLJq4oXFcLSgRRrKSl0QiwbZt2zB8+HDV2MSJE5GXl6dxJKvKhQsX4Ofnh5MnT6J79+4AgD179mDw4MG4ceMG3N3dsW7dOsyfPx9ZWVmQyWQAgLlz52L79u1ISUkBAIwePRpFRUXYuXOnats9e/ZEly5dsH79eggh4O7ujtmzZ+PNN98EAOTn58PV1RVRUVEYM2ZMrfZRoVDA3t4e+fn5kMvldf0RERERGaWS8kqUlivxr+9P4diV3Grz0v49CJOiTsKjqTWWjuisxwofT10+v41+jlVcXBxcXFzg6+uLadOm4c6dO6pYfHw8HBwcVE0VAISEhEAqleL48eOqnD59+qiaKgAIDQ1Famoq7t69q8oJCQlR+76hoaGIj78/8S49PR1ZWVlqOfb29ggKClLlaFNaWgqFQqH2ICIiamisLMxgb2OBH6b0rDGvz/IDOJx2Gz+euK6nyvTPqBurgQMH4ttvv0VsbCw+/PBDHDx4EIMGDUJl5f3LNrOysuDi4qL2GnNzczg6OiIrK0uV4+qqPrGu6vnDch6MP/g6bTnaLF26FPb29qqHp6dnnfafiIjIlJhJJTjxdn8cnav9CsDM/L+mz9wuLG2Qt78x6uUWHjzF1qlTJ3Tu3BmtWrVCXFwc+vfvb8DKamfevHmIiIhQPVcoFGyuiIioQXP532T2n6YGY9T66s/qdF+8D062MvRt64KVL1S/krupMeojVn/XsmVLODk54dKlSwAANzc35OSoX2VQUVGB3NxcuLm5qXKys7PVcqqePyznwfiDr9OWo42lpSXkcrnag4iIqDHo7uP40JzbhWX47x839FCN/phUY3Xjxg3cuXMHzZs3BwAEBwcjLy8PCQkJqpz9+/dDqVQiKChIlXPo0CGUl5ercmJiYuDr64umTZuqcmJjY9W+V0xMDIKDgwEALVq0gJubm1qOQqHA8ePHVTlEREREBm2sCgsLkZiYiMTERAD3J4knJiYiIyMDhYWFmDNnDo4dO4arV68iNjYWw4YNQ+vWrREaGgoAaN++PQYOHIhXX30VJ06cwJEjRzB9+nSMGTMG7u7uAIAXX3wRMpkMkydPRnJyMjZv3ozPPvtM7RTdG2+8gT179mDlypVISUnBe++9h1OnTmH69OkA7l+xOHPmTCxevBi//vorzp07h5dffhnu7u5qVzESERHRX+aE+hq6BL0z6HILcXFx6Nevn8b4hAkTsG7dOgwfPhynT59GXl4e3N3dMWDAAHzwwQdqk8hzc3Mxffp07NixA1KpFCNHjsSqVatga2uryjl79izCw8Nx8uRJODk5YcaMGYiMjFT7nlu3bsU777yDq1evok2bNli+fDkGDx6sigshsHDhQnz55ZfIy8vDU089hc8//xxt27at9f5yuQUiImpMyiuViL2Qjanf/1Fj3qE5/eDVzEZPVdVdXT6/jWYdq8aAjRURETVGPnOja4yHdnDFF+O7o6i0Ak1qsdiovjWodayIiIjItL0Y5KX62kfLkanfkrPxbfxVdFj4G7af/lOfpekcj1jpEY9YERFRY/XD8Wswl0rwXGd3BC2JRWFpRbW5V5eF6bGyh6vL57fxHW8jIiKiBmdckLfqaxc7yxobK1PGU4FERESkV61cbGuMZ9y5p6dKdI+NFREREemVuVRSY7zPigM4dyPfJG95w1OBREREpFfmZg8/rjNkze8AgPUvBaDjE3J4NDXe5RgexMaKiIiI9MrFzrLWuVO/v393FWOb0F4dNlZERESkV68/0wYXswswotsT8Ghqg3/UcLNmU8PGioiIiPTK3sYC300OUj3f9XpvDF512IAV6Q4nrxMREZFB+bnL8dPU4BpzKiqVeqrm8bCxIiIiIoPr7uNYY7y0Qr2xikvNwYrfUlCpNK4rB9lYERERkVEY3Mmt2lhOQana84kbTmLtgcvYefZmfZdVJ2ysiIiIyCisfbEbUhcPxOv922jEBn12SOtrMvNL6rusOmFjRUREREZBIpHA0twMEc+2xeLhHdViJeVKFJVWQPm3U39mkpoXG9U3NlZERERkdF7q6Y2LiwepjQ387BC6/3sfbtz965Y30oes4q5vbKyIiIjIKMnMpWqnBa/nFiO3qAxPfXhANfaw2+PoGxsrIiIiMlp/P/X3dzxiRURERFRL7ZvLa4zziBURERFRLQ3u5IbR3T2rjd8rq9RjNQ/HxoqIiIiMlkQiwYejOiPp/VCt8Q92nsd/Dl+BEMaxUCgbKyIiIjJ6tpbV3954cfQFzPnprB6rqR4bKyIiIjIJ7w/tUG3sp4QbOJGeq8dqtGNjRURERCZhQi8fNGsiqzb+whfxSPozX48VaWJjRURERCbD3cG6xviGI1f1U0g12FgRERGRyfhwZGfUtMLClN4t9FeMFtXPBCMiIiIyMn7uclxZGgalUuDT2DSsik1TxZxsZQ9d96q+8YgVERERmRypVKIx32p7+JMGquYvbKyIiIjIJI0J9MSIrk/c/7qHJzya2hi4IkAijGVFrUZAoVDA3t4e+fn5kMsNe6iSiIiIaqcun988YkVERESkI2ysiIiIiHSEjRURERGRjrCxIiIiItIRNlZEREREOsLGioiIiEhH2FgRERER6QgbKyIiIiIdYWNFREREpCNsrIiIiIh0hI0VERERkY6wsSIiIiLSETZWRERERDrCxoqIiIhIR8wNXUBjIoQAACgUCgNXQkRERLVV9bld9TleEzZWelRQUAAA8PT0NHAlREREVFcFBQWwt7evMUciatN+kU4olUrcvHkTdnZ2kEgkOt22QqGAp6cnrl+/DrlcrtNtGwPun+lr6PvY0PcPaPj7yP0zffW1j0IIFBQUwN3dHVJpzbOoeMRKj6RSKTw8POr1e8jl8gb7Dwbg/jUEDX0fG/r+AQ1/H7l/pq8+9vFhR6qqcPI6ERERkY6wsSIiIiLSETZWDYSlpSUWLlwIS0tLQ5dSL7h/pq+h72ND3z+g4e8j98/0GcM+cvI6ERERkY7wiBURERGRjrCxIiIiItIRNlZEREREOsLGioiIiEhH2Fg1AGvXroWPjw+srKwQFBSEEydOGLqkWlm6dCl69OgBOzs7uLi4YPjw4UhNTVXLefrppyGRSNQeU6dOVcvJyMhAWFgYbGxs4OLigjlz5qCiokKfu6LVe++9p1F7u3btVPGSkhKEh4ejWbNmsLW1xciRI5Gdna22DWPdtyo+Pj4a+yiRSBAeHg7A9N6/Q4cOYciQIXB3d4dEIsH27dvV4kIILFiwAM2bN4e1tTVCQkKQlpamlpObm4tx48ZBLpfDwcEBkydPRmFhoVrO2bNn0bt3b1hZWcHT0xPLly+v711TqWkfy8vLERkZiU6dOqFJkyZwd3fHyy+/jJs3b6ptQ9v7vmzZMrUcQ+3jw97DiRMnatQ+cOBAtRxjfg8ftn/a/j1KJBKsWLFClWPM719tPhd09bszLi4O3bp1g6WlJVq3bo2oqCjd7IQgk7Zp0yYhk8nE119/LZKTk8Wrr74qHBwcRHZ2tqFLe6jQ0FCxYcMGkZSUJBITE8XgwYOFl5eXKCwsVOX07dtXvPrqqyIzM1P1yM/PV8UrKipEx44dRUhIiDh9+rTYtWuXcHJyEvPmzTPELqlZuHCh6NChg1rtt27dUsWnTp0qPD09RWxsrDh16pTo2bOn6NWrlypuzPtWJScnR23/YmJiBABx4MABIYTpvX+7du0S8+fPFz///LMAILZt26YWX7ZsmbC3txfbt28XZ86cEUOHDhUtWrQQxcXFqpyBAwcKf39/cezYMXH48GHRunVrMXbsWFU8Pz9fuLq6inHjxomkpCTx448/Cmtra/HFF18YfB/z8vJESEiI2Lx5s0hJSRHx8fEiMDBQBAQEqG3D29tbLFq0SO19ffDfrSH38WHv4YQJE8TAgQPVas/NzVXLMeb38GH79+B+ZWZmiq+//lpIJBJx+fJlVY4xv3+1+VzQxe/OK1euCBsbGxERESHOnz8vVq9eLczMzMSePXseex/YWJm4wMBAER4ernpeWVkp3N3dxdKlSw1Y1aPJyckRAMTBgwdVY3379hVvvPFGta/ZtWuXkEqlIisrSzW2bt06IZfLRWlpaX2W+1ALFy4U/v7+WmN5eXnCwsJCbN26VTV24cIFAUDEx8cLIYx736rzxhtviFatWgmlUimEMO337+8fWkqlUri5uYkVK1aoxvLy8oSlpaX48ccfhRBCnD9/XgAQJ0+eVOXs3r1bSCQS8eeffwohhPj8889F06ZN1fYvMjJS+Pr61vMeadL2wfx3J06cEADEtWvXVGPe3t7ik08+qfY1xrKP1TVWw4YNq/Y1pvQe1ub9GzZsmHjmmWfUxkzl/RNC83NBV78733rrLdGhQwe17zV69GgRGhr62DXzVKAJKysrQ0JCAkJCQlRjUqkUISEhiI+PN2BljyY/Px8A4OjoqDb+ww8/wMnJCR07dsS8efNw7949VSw+Ph6dOnWCq6uraiw0NBQKhQLJycn6KbwGaWlpcHd3R8uWLTFu3DhkZGQAABISElBeXq723rVr1w5eXl6q987Y9+3vysrK8P3332PSpElqNxk35ffvQenp6cjKylJ7z+zt7REUFKT2njk4OKB79+6qnJCQEEilUhw/flyV06dPH8hkMlVOaGgoUlNTcffuXT3tTe3l5+dDIpHAwcFBbXzZsmVo1qwZunbtihUrVqidZjH2fYyLi4OLiwt8fX0xbdo03LlzRxVrSO9hdnY2oqOjMXnyZI2Yqbx/f/9c0NXvzvj4eLVtVOXo4rOTN2E2Ybdv30ZlZaXaXx4AcHV1RUpKioGqejRKpRIzZ87Ek08+iY4dO6rGX3zxRXh7e8Pd3R1nz55FZGQkUlNT8fPPPwMAsrKytO5/VcyQgoKCEBUVBV9fX2RmZuL9999H7969kZSUhKysLMhkMo0PK1dXV1Xdxrxv2mzfvh15eXmYOHGiasyU37+/q6pHW70PvmcuLi5qcXNzczg6OqrltGjRQmMbVbGmTZvWS/2PoqSkBJGRkRg7dqzaDW1ff/11dOvWDY6Ojjh69CjmzZuHzMxMfPzxxwCMex8HDhyIESNGoEWLFrh8+TLefvttDBo0CPHx8TAzM2tQ7+E333wDOzs7jBgxQm3cVN4/bZ8LuvrdWV2OQqFAcXExrK2tH7luNlZkFMLDw5GUlITff/9dbfyf//yn6utOnTqhefPm6N+/Py5fvoxWrVrpu8w6GTRokOrrzp07IygoCN7e3tiyZctj/aM1Vl999RUGDRoEd3d31Zgpv3+NXXl5OV544QUIIbBu3Tq1WEREhOrrzp07QyaT4V//+heWLl1q9LdLGTNmjOrrTp06oXPnzmjVqhXi4uLQv39/A1ame19//TXGjRsHKysrtXFTef+q+1wwdjwVaMKcnJxgZmamcTVEdnY23NzcDFRV3U2fPh07d+7EgQMH4OHhUWNuUFAQAODSpUsAADc3N637XxUzJg4ODmjbti0uXboENzc3lJWVIS8vTy3nwffOlPbt2rVr2LdvH6ZMmVJjnim/f1X11PTvzc3NDTk5OWrxiooK5ObmmtT7WtVUXbt2DTExMWpHq7QJCgpCRUUFrl69CsA09rFKy5Yt4eTkpPZ3siG8h4cPH0ZqaupD/00Cxvn+Vfe5oKvfndXlyOXyx/6PLxsrEyaTyRAQEIDY2FjVmFKpRGxsLIKDgw1YWe0IITB9+nRs27YN+/fv1zj0rE1iYiIAoHnz5gCA4OBgnDt3Tu0XYdUHgZ+fX73U/agKCwtx+fJlNG/eHAEBAbCwsFB771JTU5GRkaF670xp3zZs2AAXFxeEhYXVmGfK71+LFi3g5uam9p4pFAocP35c7T3Ly8tDQkKCKmf//v1QKpWqpjI4OBiHDh1CeXm5KicmJga+vr5GcQqpqqlKS0vDvn370KxZs4e+JjExEVKpVHUKzdj38UE3btzAnTt31P5Omvp7CNw/ghwQEAB/f/+H5hrT+/ewzwVd/e4MDg5W20ZVjk4+Ox97+jsZ1KZNm4SlpaWIiooS58+fF//85z+Fg4OD2tUQxmratGnC3t5exMXFqV32e+/ePSGEEJcuXRKLFi0Sp06dEunp6eKXX34RLVu2FH369FFto+qy2gEDBojExESxZ88e4ezsbBRLEsyePVvExcWJ9PR0ceTIERESEiKcnJxETk6OEOL+JcNeXl5i//794tSpUyI4OFgEBwerXm/M+/agyspK4eXlJSIjI9XGTfH9KygoEKdPnxanT58WAMTHH38sTp8+rboibtmyZcLBwUH88ssv4uzZs2LYsGFal1vo2rWrOH78uPj9999FmzZt1C7Vz8vLE66urmL8+PEiKSlJbNq0SdjY2OhtuYWa9rGsrEwMHTpUeHh4iMTERLV/l1VXUx09elR88sknIjExUVy+fFl8//33wtnZWbz88stGsY817V9BQYF48803RXx8vEhPTxf79u0T3bp1E23atBElJSWqbRjze/iwv6NC3F8uwcbGRqxbt07j9cb+/j3sc0EI3fzurFpuYc6cOeLChQti7dq1XG6B/rJ69Wrh5eUlZDKZCAwMFMeOHTN0SbUCQOtjw4YNQgghMjIyRJ8+fYSjo6OwtLQUrVu3FnPmzFFbB0kIIa5evSoGDRokrK2thZOTk5g9e7YoLy83wB6pGz16tGjevLmQyWTiiSeeEKNHjxaXLl1SxYuLi8Vrr70mmjZtKmxsbMTzzz8vMjMz1bZhrPv2oN9++00AEKmpqWrjpvj+HThwQOvfyQkTJggh7i+58O677wpXV1dhaWkp+vfvr7Hfd+7cEWPHjhW2trZCLpeLV155RRQUFKjlnDlzRjz11FPC0tJSPPHEE2LZsmX62sUa9zE9Pb3af5dVa5MlJCSIoKAgYW9vL6ysrET79u3FkiVL1BoTQ+5jTft37949MWDAAOHs7CwsLCyEt7e3ePXVVzX+I2rM7+HD/o4KIcQXX3whrK2tRV5ensbrjf39e9jnghC6+9154MAB0aVLFyGTyUTLli3VvsfjkPxvR4iIiIjoMXGOFREREZGOsLEiIiIi0hE2VkREREQ6wsaKiIiISEfYWBERERHpCBsrIiIiIh1hY0VERESkI2ysiIiIiHSEjRURkR7FxcVBIpFo3ESWiBoGNlZEREREOsLGioiIiEhH2FgRUaOiVCqxdOlStGjRAtbW1vD398dPP/0E4K/TdNHR0ejcuTOsrKzQs2dPJCUlqW3jv//9Lzp06ABLS0v4+Phg5cqVavHS0lJERkbC09MTlpaWaN26Nb766iu1nISEBHTv3h02Njbo1asXUlNTVbEzZ86gX79+sLOzg1wuR0BAAE6dOlVPPxEi0iU2VkTUqCxduhTffvst1q9fj+TkZMyaNQsvvfQSDh48qMqZM2cOVq5ciZMnT8LZ2RlDhgxBeXk5gPsN0QsvvIAxY8bg3LlzeO+99/Duu+8iKipK9fqXX34ZP/74I1atWoULFy7giy++gK2trVod8+fPx8qVK3Hq1CmYm5tj0qRJqti4cePg4eGBkydPIiEhAXPnzoWFhUX9/mCISDcEEVEjUVJSImxsbMTRo0fVxidPnizGjh0rDhw4IACITZs2qWJ37twR1tbWYvPmzUIIIV588UXx7LPPqr1+zpw5ws/PTwghRGpqqgAgYmJitNZQ9T327dunGouOjhYARHFxsRBCCDs7OxEVFfX4O0xEescjVkTUaFy6dAn37t3Ds88+C1tbW9Xj22+/xeXLl1V5wcHBqq8dHR3h6+uLCxcuAAAuXLiAJ598Um27Tz75JNLS0lBZWYnExESYmZmhb9++NdbSuXNn1dfNmzcHAOTk5AAAIiIiMGXKFISEhGDZsmVqtRGRcWNjRUSNRmFhIQAgOjoaiYmJqsf58+dV86wel7W1da3yHjy1J5FIANyf/wUA7733HpKTkxEWFob9+/fDz88P27Zt00l9RFS/2FgRUaPh5+cHS0tLZGRkoHXr1moPT09PVd6xY8dUX9+9excXL15E+/btAQDt27fHkSNH1LZ75MgRtG3bFmZmZujUqROUSqXanK1H0bZtW8yaNQt79+7FiBEjsGHDhsfaHhHph7mhCyAi0hc7Ozu8+eabmDVrFpRKJZ566ink5+fjyJEjkMvl8Pb2BgAsWrQIzZo1g6urK+bPnw8nJycMHz4cADB79mz06NEDH3zwAUaPHo34+HisWbMGn3/+OQDAx8cHEyZMwKRJk7Bq1Sr4+/vj2rVryMnJwQsvvPDQGouLizFnzhyMGjUKLVq0wI0bN3Dy5EmMHDmy3n4uRKRDhp7kRUSkT0qlUnz66afC19dXWFhYCGdnZxEaGioOHjyomli+Y8cO0aFDByGTyURgYKA4c+aM2jZ++ukn4efnJywsLISXl5dYsWKFWry4uFjMmjVLNG/eXMhkMtG6dWvx9ddfCyH+mrx+9+5dVf7p06cFAJGeni5KS0vFmDFjhKenp5DJZMLd3V1Mnz5dNbGdiIybRAghDNzbEREZhbi4OPTr1w93796Fg4ODocshIhPEOVZEREREOsLGioiIiEhHeCqQiIiISEd4xIqIiIhIR9hYEREREekIGysiIiIiHWFjRURERKQjbKyIiIiIdISNFREREZGOsLEiIiIi0hE2VkREREQ68v+/KK3y4fbFBAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_losses = [loss.detach().numpy() if hasattr(loss, 'detach') else loss for loss in final_losses]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(epochs), final_losses)\n",
    "plt.ylabel(\"EMSE LOSS\")\n",
    "plt.xlabel(\"epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 139563.875\n"
     ]
    }
   ],
   "source": [
    "# Validate the test data\n",
    "\n",
    "y_pred = \"\"\n",
    "with torch.no_grad():\n",
    "    y_pred = model(test_categorical, test_cont)\n",
    "    loss = torch.sqrt(loss_function(y_pred, y_test))\n",
    "print(f\"RMSE: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_verify = pd.DataFrame(y_test.tolist(), columns=[\"Test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_predicted = pd.DataFrame(y_pred.tolist(), columns=[\"Prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44052.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31064.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33538.335938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89223.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37991.621094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>62336.996094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56611.121094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>101960.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26918.183594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>129863.234375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Prediction\n",
       "0   44052.769531\n",
       "1   31064.375000\n",
       "2   33538.335938\n",
       "3   89223.781250\n",
       "4   37991.621094\n",
       "5   62336.996094\n",
       "6   56611.121094\n",
       "7  101960.671875\n",
       "8   26918.183594\n",
       "9  129863.234375"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_predicted[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130000.0</td>\n",
       "      <td>44052.769531</td>\n",
       "      <td>85947.230469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138887.0</td>\n",
       "      <td>31064.375000</td>\n",
       "      <td>107822.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175500.0</td>\n",
       "      <td>33538.335938</td>\n",
       "      <td>141961.664062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195000.0</td>\n",
       "      <td>89223.781250</td>\n",
       "      <td>105776.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142500.0</td>\n",
       "      <td>37991.621094</td>\n",
       "      <td>104508.378906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Test    Prediction     Difference\n",
       "0  130000.0  44052.769531   85947.230469\n",
       "1  138887.0  31064.375000  107822.625000\n",
       "2  175500.0  33538.335938  141961.664062\n",
       "3  195000.0  89223.781250  105776.218750\n",
       "4  142500.0  37991.621094  104508.378906"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output = pd.concat([data_verify, data_predicted], axis=1)\n",
    "final_output['Difference'] = final_output['Test'] - final_output['Prediction']\n",
    "final_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'HousePrice.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'HouseWeights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the save model\n",
    "\n",
    "embs_size = [(15, 8), (5,3), (2,1), (4,2)]\n",
    "model1 = FeedForwardNN(embs_size, 5, 1, [100, 50], p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2260927\\AppData\\Local\\Temp\\ipykernel_14364\\2229105223.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model1.load_state_dict(torch.load('HouseWeights.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.load_state_dict(torch.load('HouseWeights.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedForwardNN(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(15, 8)\n",
       "    (1): Embedding(5, 3)\n",
       "    (2): Embedding(2, 1)\n",
       "    (3): Embedding(4, 2)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=19, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
