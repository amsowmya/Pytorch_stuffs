{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data = [[1,2], [3, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [3, 4]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(some_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(some_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(some_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data = torch.tensor(some_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(some_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_array = np.random.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94879738, 0.89478978, 0.24618004, 0.65830105],\n",
       "       [0.72595834, 0.02194062, 0.75283125, 0.88318738],\n",
       "       [0.08767664, 0.39069738, 0.40583861, 0.03664323]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9488, 0.8948, 0.2462, 0.6583],\n",
       "        [0.7260, 0.0219, 0.7528, 0.8832],\n",
       "        [0.0877, 0.3907, 0.4058, 0.0366]], dtype=torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9488, 0.8948, 0.2462, 0.6583],\n",
       "        [0.7260, 0.0219, 0.7528, 0.8832],\n",
       "        [0.0877, 0.3907, 0.4058, 0.0366]], dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1117, 0.1742, 0.1115, 0.0793],\n",
       "        [0.3784, 0.9398, 0.6209, 0.2525],\n",
       "        [0.6775, 0.9606, 0.5284, 0.9071]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tensor = torch.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_tensor.to(\"cuda\")\n",
    "# my_tensor = my_tensor.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7580, 0.0770],\n",
       "        [0.6239, 0.6543],\n",
       "        [0.8037, 0.2447]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor[:, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2010, 0.5746, 0.0059, 0.0310],\n",
       "        [0.0780, 0.3892, 0.4281, 0.0011],\n",
       "        [0.7176, 0.6459, 0.0599, 0.5814]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.mul(my_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2010, 0.5746, 0.0059, 0.0310],\n",
       "        [0.0780, 0.3892, 0.4281, 0.0011],\n",
       "        [0.7176, 0.6459, 0.0599, 0.5814]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor * my_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8125, 0.6544, 1.1421],\n",
       "        [0.6544, 0.8964, 0.9236],\n",
       "        [1.1421, 0.9236, 2.0047]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.matmul(my_tensor.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8125, 0.6544, 1.1421],\n",
       "        [0.6544, 0.8964, 0.9236],\n",
       "        [1.1421, 0.9236, 2.0047]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(my_tensor, my_tensor.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8125, 0.6544, 1.1421],\n",
       "        [0.6544, 0.8964, 0.9236],\n",
       "        [1.1421, 0.9236, 2.0047]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor @ my_tensor.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.7083)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4594, 1.5909, 2.6580])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.max, torch.min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4483, 0.7580, 0.0770, 0.1761],\n",
       "        [0.2792, 0.6239, 0.6543, 0.0336],\n",
       "        [0.8471, 0.8037, 0.2447, 0.7625],\n",
       "        [0.4483, 0.7580, 0.0770, 0.1761],\n",
       "        [0.2792, 0.6239, 0.6543, 0.0336],\n",
       "        [0.8471, 0.8037, 0.2447, 0.7625]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([my_tensor, my_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4483, 0.7580, 0.0770, 0.1761, 0.4483, 0.7580, 0.0770, 0.1761],\n",
       "        [0.2792, 0.6239, 0.6543, 0.0336, 0.2792, 0.6239, 0.6543, 0.0336],\n",
       "        [0.8471, 0.8037, 0.2447, 0.7625, 0.8471, 0.8037, 0.2447, 0.7625]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([my_tensor, my_tensor], axis=1)\n",
    "# torch.cat([my_tensor, my_tensor], dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4483, 0.7580, 0.0770, 0.1761],\n",
       "        [0.2792, 0.6239, 0.6543, 0.0336],\n",
       "        [0.8471, 0.8037, 0.2447, 0.7625]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2622, 0.3573, 0.1808, 0.1997],\n",
       "        [0.2151, 0.3036, 0.3130, 0.1683],\n",
       "        [0.2921, 0.2796, 0.1599, 0.2684]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(my_tensor, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2999, 0.3423, 0.2523, 0.2729],\n",
       "        [0.2532, 0.2994, 0.4494, 0.2366],\n",
       "        [0.4469, 0.3583, 0.2984, 0.4905]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(my_tensor, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.size()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[8.9982e-01, 9.4285e-01, 7.7945e-02,  ..., 4.5431e-01,\n",
       "           1.1518e-01, 2.8151e-01],\n",
       "          [9.1014e-01, 2.5449e-01, 2.3238e-01,  ..., 5.9213e-01,\n",
       "           8.8869e-01, 1.1276e-01],\n",
       "          [6.4573e-01, 3.7433e-01, 5.0916e-01,  ..., 8.0527e-01,\n",
       "           5.6795e-01, 8.7214e-01],\n",
       "          ...,\n",
       "          [1.0492e-01, 2.3322e-01, 4.3459e-01,  ..., 6.5166e-01,\n",
       "           1.8782e-01, 5.0753e-01],\n",
       "          [4.9301e-01, 9.0072e-01, 5.6279e-01,  ..., 3.2460e-01,\n",
       "           6.4834e-01, 6.3211e-01],\n",
       "          [8.9624e-01, 8.5826e-01, 5.7957e-01,  ..., 7.6280e-01,\n",
       "           8.6849e-01, 3.3041e-01]],\n",
       "\n",
       "         [[2.4665e-01, 6.4405e-01, 5.8757e-01,  ..., 9.8014e-02,\n",
       "           7.9276e-02, 7.3217e-01],\n",
       "          [5.6036e-01, 4.4311e-01, 1.2250e-01,  ..., 4.0430e-01,\n",
       "           8.5714e-01, 7.7864e-01],\n",
       "          [6.9022e-01, 2.4362e-01, 5.8308e-01,  ..., 3.8385e-01,\n",
       "           8.2269e-01, 4.1911e-01],\n",
       "          ...,\n",
       "          [7.8645e-01, 9.3483e-01, 4.0956e-03,  ..., 6.9612e-01,\n",
       "           5.5719e-01, 4.9230e-02],\n",
       "          [8.7178e-02, 4.4976e-01, 8.2024e-01,  ..., 8.5382e-01,\n",
       "           3.2707e-01, 6.6328e-01],\n",
       "          [2.4348e-01, 7.0554e-01, 9.9302e-01,  ..., 8.9971e-01,\n",
       "           6.5447e-01, 3.4538e-01]],\n",
       "\n",
       "         [[2.3462e-01, 3.0467e-01, 9.6117e-01,  ..., 2.6933e-01,\n",
       "           2.5183e-01, 6.2326e-01],\n",
       "          [8.9770e-01, 8.8400e-01, 5.9474e-01,  ..., 7.9346e-01,\n",
       "           4.0624e-01, 6.3628e-04],\n",
       "          [1.6459e-01, 4.7033e-01, 1.2005e-01,  ..., 1.6672e-01,\n",
       "           1.4066e-03, 7.2115e-01],\n",
       "          ...,\n",
       "          [8.5717e-01, 6.6080e-01, 8.2265e-01,  ..., 5.7795e-02,\n",
       "           4.0546e-01, 2.0482e-01],\n",
       "          [1.4699e-01, 4.7879e-01, 4.9490e-01,  ..., 2.4526e-01,\n",
       "           1.9885e-01, 3.3968e-02],\n",
       "          [5.8991e-01, 2.8344e-01, 5.4691e-01,  ..., 2.9500e-01,\n",
       "           9.2828e-01, 2.5761e-01]]],\n",
       "\n",
       "\n",
       "        [[[5.7716e-01, 4.7312e-01, 8.5481e-01,  ..., 9.7132e-01,\n",
       "           4.5458e-01, 7.3592e-01],\n",
       "          [4.8096e-01, 7.5664e-01, 6.3404e-01,  ..., 2.1553e-01,\n",
       "           1.7321e-01, 8.2236e-01],\n",
       "          [5.7457e-01, 7.3277e-01, 2.7377e-01,  ..., 6.6595e-01,\n",
       "           9.2043e-01, 8.4708e-01],\n",
       "          ...,\n",
       "          [9.5951e-01, 2.9277e-01, 6.6576e-01,  ..., 3.1838e-01,\n",
       "           3.2633e-01, 2.3359e-01],\n",
       "          [1.6083e-01, 4.9277e-01, 7.8587e-02,  ..., 1.8749e-01,\n",
       "           9.3362e-01, 3.7980e-01],\n",
       "          [4.5251e-01, 1.4912e-01, 3.5730e-01,  ..., 6.4205e-01,\n",
       "           8.7511e-01, 6.1762e-01]],\n",
       "\n",
       "         [[2.7860e-01, 3.0885e-01, 2.7506e-01,  ..., 6.4136e-01,\n",
       "           5.6861e-01, 8.3125e-01],\n",
       "          [5.5327e-01, 1.2308e-01, 7.8524e-01,  ..., 2.2538e-01,\n",
       "           2.2868e-01, 6.2170e-02],\n",
       "          [7.7976e-01, 6.2925e-01, 6.0247e-01,  ..., 3.2766e-01,\n",
       "           7.8180e-01, 9.9761e-01],\n",
       "          ...,\n",
       "          [3.1078e-01, 6.5369e-01, 3.1641e-01,  ..., 2.3843e-01,\n",
       "           2.7753e-01, 5.9743e-01],\n",
       "          [3.1350e-01, 1.8427e-01, 8.8990e-01,  ..., 6.9468e-01,\n",
       "           4.1986e-01, 1.9394e-01],\n",
       "          [2.2842e-01, 9.9028e-01, 6.7103e-01,  ..., 1.7995e-01,\n",
       "           1.7606e-02, 2.8468e-02]],\n",
       "\n",
       "         [[2.4113e-01, 6.9964e-01, 1.2726e-02,  ..., 9.6298e-01,\n",
       "           8.3097e-01, 9.3734e-01],\n",
       "          [5.8485e-01, 6.2642e-01, 1.0335e-01,  ..., 6.2166e-01,\n",
       "           2.3023e-01, 1.1818e-01],\n",
       "          [6.2274e-01, 8.6348e-01, 7.4124e-01,  ..., 1.1660e-01,\n",
       "           3.6032e-01, 3.7280e-01],\n",
       "          ...,\n",
       "          [5.5522e-01, 2.7829e-01, 7.8256e-01,  ..., 2.0006e-01,\n",
       "           9.7941e-01, 2.3719e-01],\n",
       "          [3.0874e-01, 3.9413e-01, 5.7372e-01,  ..., 4.5261e-01,\n",
       "           5.6536e-01, 8.4716e-01],\n",
       "          [2.6099e-01, 2.3333e-01, 7.6849e-01,  ..., 8.8472e-01,\n",
       "           2.3331e-01, 1.1191e-01]]],\n",
       "\n",
       "\n",
       "        [[[5.3043e-01, 1.7001e-01, 5.5250e-02,  ..., 9.8927e-01,\n",
       "           4.0243e-01, 4.8918e-01],\n",
       "          [9.8942e-01, 5.9695e-01, 6.6166e-01,  ..., 3.0298e-01,\n",
       "           6.6299e-01, 4.8021e-01],\n",
       "          [6.2131e-01, 8.6164e-01, 3.7065e-01,  ..., 5.0743e-01,\n",
       "           7.7224e-01, 8.2631e-01],\n",
       "          ...,\n",
       "          [5.0806e-01, 4.7204e-01, 1.9874e-01,  ..., 1.8920e-01,\n",
       "           8.6321e-01, 9.2102e-01],\n",
       "          [9.1253e-01, 1.2870e-01, 5.8429e-01,  ..., 3.7644e-01,\n",
       "           3.3096e-01, 3.1219e-01],\n",
       "          [7.9597e-01, 2.0860e-01, 9.5327e-01,  ..., 9.6559e-01,\n",
       "           5.3594e-01, 2.1644e-01]],\n",
       "\n",
       "         [[5.7042e-01, 9.8674e-01, 6.9577e-01,  ..., 9.9412e-01,\n",
       "           7.1239e-01, 3.9650e-01],\n",
       "          [7.4686e-01, 6.0738e-01, 8.5846e-01,  ..., 1.2581e-01,\n",
       "           8.7390e-01, 1.5812e-01],\n",
       "          [1.1886e-02, 6.6625e-01, 1.1307e-01,  ..., 4.4887e-01,\n",
       "           5.7691e-01, 9.3198e-01],\n",
       "          ...,\n",
       "          [9.3627e-01, 5.2557e-01, 4.4977e-01,  ..., 7.4236e-01,\n",
       "           9.3291e-01, 5.7528e-01],\n",
       "          [8.1126e-01, 6.0916e-02, 2.3127e-03,  ..., 1.9742e-01,\n",
       "           2.0692e-01, 3.9583e-01],\n",
       "          [3.1999e-01, 8.5225e-01, 1.0720e-01,  ..., 5.7854e-02,\n",
       "           1.1965e-01, 6.8134e-01]],\n",
       "\n",
       "         [[9.6229e-01, 2.8098e-01, 9.1850e-01,  ..., 2.2103e-01,\n",
       "           5.1502e-01, 1.0228e-02],\n",
       "          [3.5285e-01, 1.0476e-01, 5.6896e-01,  ..., 4.4590e-02,\n",
       "           5.1989e-01, 6.0584e-01],\n",
       "          [1.8182e-01, 6.2828e-01, 3.1566e-01,  ..., 3.0259e-01,\n",
       "           9.4201e-01, 5.5663e-01],\n",
       "          ...,\n",
       "          [2.6434e-02, 2.6889e-01, 2.5548e-01,  ..., 2.1014e-01,\n",
       "           1.0112e-01, 6.8644e-01],\n",
       "          [4.1112e-01, 9.1243e-01, 2.2033e-01,  ..., 9.6072e-01,\n",
       "           8.7888e-01, 2.1040e-02],\n",
       "          [9.7900e-01, 9.0029e-01, 5.5467e-01,  ..., 6.7287e-01,\n",
       "           5.0770e-01, 7.5940e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[2.3750e-01, 9.8230e-01, 5.0595e-01,  ..., 6.7708e-01,\n",
       "           4.4883e-01, 1.5944e-01],\n",
       "          [4.8514e-01, 7.7434e-01, 4.4463e-01,  ..., 6.0973e-01,\n",
       "           5.7564e-01, 5.5264e-01],\n",
       "          [9.0922e-01, 4.9296e-01, 8.5933e-01,  ..., 8.0837e-01,\n",
       "           8.3827e-01, 2.5225e-01],\n",
       "          ...,\n",
       "          [8.5382e-01, 9.6320e-01, 7.2033e-01,  ..., 1.1967e-01,\n",
       "           1.0520e-02, 9.4713e-01],\n",
       "          [1.2179e-01, 6.8273e-01, 1.7541e-01,  ..., 2.7364e-03,\n",
       "           9.6237e-01, 3.1208e-01],\n",
       "          [3.1664e-01, 2.6863e-01, 8.1674e-01,  ..., 4.8240e-01,\n",
       "           5.3409e-02, 4.0933e-01]],\n",
       "\n",
       "         [[2.1304e-01, 1.6914e-01, 9.3191e-01,  ..., 3.5468e-01,\n",
       "           6.7104e-01, 7.7410e-01],\n",
       "          [9.0016e-01, 1.0059e-01, 2.3941e-02,  ..., 6.0796e-01,\n",
       "           6.0982e-01, 5.3656e-01],\n",
       "          [1.0162e-01, 4.4353e-01, 6.9903e-01,  ..., 8.1819e-01,\n",
       "           2.2022e-02, 9.8841e-01],\n",
       "          ...,\n",
       "          [6.5644e-02, 7.0499e-01, 9.0573e-01,  ..., 3.9705e-01,\n",
       "           4.8837e-01, 8.1984e-01],\n",
       "          [3.1317e-01, 5.8203e-01, 3.2531e-01,  ..., 1.6792e-01,\n",
       "           9.8329e-01, 5.6243e-01],\n",
       "          [8.4795e-01, 2.5678e-01, 9.1723e-01,  ..., 6.3999e-01,\n",
       "           1.9133e-01, 9.3712e-01]],\n",
       "\n",
       "         [[9.1048e-01, 1.1083e-02, 6.1899e-01,  ..., 4.2152e-01,\n",
       "           5.1059e-02, 2.7845e-01],\n",
       "          [2.5588e-01, 2.7873e-02, 7.2104e-01,  ..., 7.1747e-01,\n",
       "           7.9004e-01, 4.6275e-01],\n",
       "          [2.1859e-03, 3.7855e-01, 9.7229e-01,  ..., 6.8013e-01,\n",
       "           3.6708e-01, 6.7885e-01],\n",
       "          ...,\n",
       "          [7.2165e-01, 5.0164e-02, 3.2902e-02,  ..., 2.8122e-01,\n",
       "           6.9317e-01, 2.0226e-01],\n",
       "          [1.1208e-01, 1.5985e-01, 1.5791e-01,  ..., 3.8875e-01,\n",
       "           5.6658e-01, 3.8297e-01],\n",
       "          [6.7098e-01, 3.3151e-02, 9.5094e-01,  ..., 6.7148e-01,\n",
       "           7.2547e-01, 2.3416e-02]]],\n",
       "\n",
       "\n",
       "        [[[3.8148e-01, 4.6362e-01, 8.1258e-01,  ..., 9.6543e-01,\n",
       "           3.7332e-01, 4.1187e-01],\n",
       "          [1.7774e-01, 6.6371e-01, 8.7014e-02,  ..., 6.7336e-01,\n",
       "           9.4010e-01, 2.9048e-01],\n",
       "          [2.7638e-01, 9.1995e-01, 7.4026e-02,  ..., 3.0932e-01,\n",
       "           6.1760e-01, 4.1404e-01],\n",
       "          ...,\n",
       "          [7.1496e-01, 5.5466e-01, 2.3589e-01,  ..., 2.1127e-01,\n",
       "           7.8424e-01, 5.6751e-01],\n",
       "          [1.9712e-01, 1.0992e-01, 8.2745e-01,  ..., 2.5913e-02,\n",
       "           3.0771e-01, 1.9470e-01],\n",
       "          [4.8403e-01, 3.1531e-01, 1.3491e-01,  ..., 1.8389e-01,\n",
       "           7.0637e-01, 8.5037e-01]],\n",
       "\n",
       "         [[2.6302e-01, 9.9234e-01, 9.2513e-01,  ..., 8.9782e-01,\n",
       "           5.3637e-01, 3.0031e-01],\n",
       "          [1.5397e-01, 7.9604e-01, 1.7035e-01,  ..., 4.9837e-01,\n",
       "           2.5708e-01, 6.5054e-01],\n",
       "          [5.0949e-01, 4.4782e-03, 4.0430e-01,  ..., 8.8189e-01,\n",
       "           6.3302e-01, 6.0245e-01],\n",
       "          ...,\n",
       "          [5.0042e-01, 9.7548e-01, 5.3090e-01,  ..., 1.9770e-01,\n",
       "           1.7902e-01, 5.7806e-01],\n",
       "          [8.6993e-01, 8.2514e-01, 7.3303e-01,  ..., 2.5129e-02,\n",
       "           3.4142e-01, 8.5736e-01],\n",
       "          [9.2789e-02, 7.3744e-01, 1.6632e-01,  ..., 4.1327e-01,\n",
       "           8.3168e-02, 9.1437e-01]],\n",
       "\n",
       "         [[2.7865e-01, 6.2772e-01, 5.4269e-01,  ..., 1.9374e-01,\n",
       "           4.3212e-01, 1.5526e-01],\n",
       "          [7.9487e-01, 9.1829e-01, 4.2113e-02,  ..., 2.3971e-01,\n",
       "           2.4568e-01, 5.8977e-01],\n",
       "          [7.8952e-01, 2.3443e-01, 1.9851e-01,  ..., 8.4584e-01,\n",
       "           4.0448e-01, 7.2192e-01],\n",
       "          ...,\n",
       "          [6.6874e-01, 6.8751e-01, 3.2850e-01,  ..., 7.2336e-01,\n",
       "           4.3106e-01, 4.1921e-01],\n",
       "          [1.0324e-01, 2.4315e-01, 6.9756e-01,  ..., 9.7611e-01,\n",
       "           3.7919e-01, 5.2953e-01],\n",
       "          [3.1447e-01, 3.4217e-01, 3.1992e-01,  ..., 1.0781e-02,\n",
       "           1.8622e-01, 8.2630e-01]]],\n",
       "\n",
       "\n",
       "        [[[6.0210e-01, 8.5403e-01, 4.2226e-01,  ..., 3.3134e-01,\n",
       "           6.8070e-01, 1.3865e-03],\n",
       "          [3.0719e-01, 1.5997e-01, 2.6852e-03,  ..., 3.7816e-01,\n",
       "           2.8461e-01, 6.8938e-01],\n",
       "          [2.8062e-01, 7.5084e-01, 9.8139e-01,  ..., 1.3701e-01,\n",
       "           3.2293e-01, 6.6405e-01],\n",
       "          ...,\n",
       "          [8.4770e-01, 2.2580e-01, 5.8061e-01,  ..., 2.4211e-01,\n",
       "           5.7775e-01, 3.2824e-01],\n",
       "          [1.5839e-01, 9.0013e-01, 3.8785e-01,  ..., 8.1105e-01,\n",
       "           2.5385e-01, 3.7798e-01],\n",
       "          [3.1993e-01, 4.0042e-01, 4.6720e-01,  ..., 2.3066e-01,\n",
       "           1.7265e-01, 2.5947e-01]],\n",
       "\n",
       "         [[8.0329e-01, 7.7225e-01, 3.8331e-01,  ..., 4.0641e-02,\n",
       "           9.4123e-01, 2.8854e-01],\n",
       "          [7.5229e-01, 8.7748e-01, 3.0860e-01,  ..., 3.9978e-01,\n",
       "           6.2006e-01, 1.9329e-01],\n",
       "          [7.2615e-02, 5.9739e-01, 2.2175e-01,  ..., 3.1612e-02,\n",
       "           3.2285e-01, 2.9594e-01],\n",
       "          ...,\n",
       "          [6.9759e-01, 5.4474e-01, 1.0577e-01,  ..., 2.1604e-01,\n",
       "           4.4482e-01, 8.1967e-01],\n",
       "          [3.5404e-01, 5.8126e-01, 6.2544e-01,  ..., 9.0008e-01,\n",
       "           9.6119e-01, 2.2204e-01],\n",
       "          [2.9891e-02, 8.7880e-01, 6.3218e-02,  ..., 4.4782e-01,\n",
       "           9.1200e-01, 6.5969e-01]],\n",
       "\n",
       "         [[4.6668e-01, 2.5354e-01, 4.2110e-01,  ..., 4.7373e-01,\n",
       "           3.3148e-01, 1.4941e-01],\n",
       "          [8.2032e-01, 9.2118e-01, 5.0261e-01,  ..., 3.2788e-01,\n",
       "           5.0229e-03, 1.9137e-01],\n",
       "          [4.5442e-02, 9.0310e-01, 1.4525e-01,  ..., 3.6084e-01,\n",
       "           9.2334e-01, 5.2934e-01],\n",
       "          ...,\n",
       "          [6.2051e-01, 6.0591e-01, 6.4086e-01,  ..., 7.6171e-01,\n",
       "           5.9001e-01, 9.6401e-01],\n",
       "          [9.8991e-01, 5.5141e-03, 5.3494e-01,  ..., 3.4746e-01,\n",
       "           4.2651e-01, 5.4501e-01],\n",
       "          [7.3635e-01, 8.7226e-01, 1.8922e-01,  ..., 1.3508e-01,\n",
       "           6.5408e-01, 1.8580e-01]]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 -> Batch size, 3 -> no of channels, 128, 128 -> image width and height\n",
    "torch.rand(10, 3, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 128, 128])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(10, 3, 128, 128).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4483, 0.7580, 0.2000, 0.2000],\n",
       "        [0.2792, 0.6239, 0.6543, 0.2000],\n",
       "        [0.8000, 0.8000, 0.2447, 0.7625]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.clip(0.2, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4483139 , 0.7580285 , 0.07699257, 0.17608094],\n",
       "       [0.2792107 , 0.62388355, 0.654262  , 0.0335716 ],\n",
       "       [0.84708434, 0.8036536 , 0.24472791, 0.76252323]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From tensor to numpy array\n",
    "my_tensor.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
